{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries and basics"
      ],
      "metadata": {
        "id": "xjIPkpQJkSEJ"
      },
      "id": "xjIPkpQJkSEJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "departmental-yorkshire",
      "metadata": {
        "id": "departmental-yorkshire"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "\n",
        "#basics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "#stats\n",
        "import math, time, random, datetime\n",
        "\n",
        "#visualizing missing values\n",
        "import missingno as msno\n",
        "\n",
        "#processing data\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n",
        "\n",
        "#spliting and testing data\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold, GridSearchCV\n",
        "from sklearn import metrics, model_selection, tree, preprocessing, linear_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#machine learning models\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\n",
        "from sklearn.svm import SVC, SVR, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# model tuning\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#colors to be used\n",
        "PURPLE = '\\033[95m'\n",
        "CYAN = '\\033[96m'\n",
        "DARKCYAN = '\\033[36m'\n",
        "BLUE = '\\033[94m'\n",
        "GREEN = '\\033[92m'\n",
        "YELLOW = '\\033[93m'\n",
        "RED = '\\033[91m'\n",
        "BOLD = '\\033[1m'\n",
        "UNDERLINE = '\\033[4m'\n",
        "END = '\\033[0m'\n",
        "\n",
        "df = pd.read_csv('data/housing_opt2.csv')\n",
        "\n",
        "from ml import Model\n",
        "data = Model(df,ycol='median_house_value',scaler='Standard')\n",
        "x_train,x_test,y_train,y_test = data.return_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acknowledged-rainbow",
      "metadata": {
        "id": "acknowledged-rainbow",
        "outputId": "affe4182-844a-41a7-c13b-c4f0c9a2bc3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 0.8007961154759966\n",
            "Accuracy Test: 0.7659463807014664\n"
          ]
        }
      ],
      "source": [
        "#found on solution notebook\n",
        "\n",
        "algo = SVR(C=157055.10989448498, gamma=0.26497040005002437,\n",
        "           kernel= 'rbf')\n",
        "model = algo.fit(x_train,y_train)\n",
        "\n",
        "acc_train = model.score(x_train,y_train)\n",
        "acc_test = model.score(x_test,y_test)\n",
        "print(\"Accuracy Train: %s\" % acc_train)\n",
        "print(\"Accuracy Test: %s\" % acc_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "atlantic-brighton",
      "metadata": {
        "id": "atlantic-brighton"
      },
      "source": [
        "#### Comparison between feature engineerings\n",
        "- Around 50% accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "entitled-probability",
      "metadata": {
        "id": "entitled-probability",
        "outputId": "bf69e917-3868-4b70-94c5-d715e8ddd496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 49.42\n",
            "Accuracy Test: 47.72\n",
            "Accuracy CV 10-Fold: [0.50988298 0.45572691 0.29989728 0.52869811 0.47762385 0.431363\n",
            " 0.39709441 0.16384388 0.39408996 0.51499983]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('data/housing_opt1.csv')\n",
        "df\n",
        "\n",
        "from ml import Model\n",
        "\n",
        "model = Model(df,ycol='median_income',scaler='Standard')\n",
        "\n",
        "avr_model = model.apply_SVR(accs='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aerial-discussion",
      "metadata": {
        "id": "aerial-discussion",
        "outputId": "55a98404-03bc-4f7b-f34b-2ea6a5ec931f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 49.51\n",
            "Accuracy Test: 47.81\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('data/housing_opt2.csv')\n",
        "df\n",
        "\n",
        "from ml import Model\n",
        "\n",
        "model = Model(df,ycol='median_income',scaler='Standard')\n",
        "\n",
        "avr_model = model.apply_SVR(accs='simple')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reserved-twins",
      "metadata": {
        "id": "reserved-twins",
        "outputId": "368cf352-d1dc-41c4-f953-c51727029b59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 49.4\n",
            "Accuracy Test: 47.71\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('data/housing_opt3.csv')\n",
        "df\n",
        "\n",
        "from ml import Model\n",
        "\n",
        "model = Model(df,ycol='median_income',scaler='Standard')\n",
        "\n",
        "avr_model = model.apply_SVR(accs='simple')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "voluntary-jaguar",
      "metadata": {
        "id": "voluntary-jaguar",
        "outputId": "3fb9aa1b-728c-4f22-f52a-7692dcaa65e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 49.48\n",
            "Accuracy Test: 47.79\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('data/housing_opt4.csv')\n",
        "df\n",
        "\n",
        "from ml import Model\n",
        "\n",
        "model = Model(df,ycol='median_income',scaler='Standard')\n",
        "\n",
        "avr_model = model.apply_SVR(accs='simple')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prescription-basics",
      "metadata": {
        "id": "prescription-basics"
      },
      "source": [
        "# Complete Model: Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "recognized-vision",
      "metadata": {
        "id": "recognized-vision",
        "outputId": "3bcb2261-ecc4-47f5-94eb-c21ccfb9c2ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>NEAR WATER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>452600.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>358500.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>352100.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>341300.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>342200.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -122.23     37.88                41.0        880.0           129.0   \n",
              "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
              "2    -122.24     37.85                52.0       1467.0           190.0   \n",
              "3    -122.25     37.85                52.0       1274.0           235.0   \n",
              "4    -122.25     37.85                52.0       1627.0           280.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  NEAR WATER  \n",
              "0       322.0       126.0         8.3252            452600.0           1  \n",
              "1      2401.0      1138.0         8.3014            358500.0           1  \n",
              "2       496.0       177.0         7.2574            352100.0           1  \n",
              "3       558.0       219.0         5.6431            341300.0           1  \n",
              "4       565.0       259.0         3.8462            342200.0           1  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('data/housing_opt2.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "forward-spokesman",
      "metadata": {
        "id": "forward-spokesman"
      },
      "outputs": [],
      "source": [
        "from ml import Model\n",
        "data = Model(df,ycol='median_house_value',scaler='Standard')\n",
        "x_train,x_test,y_train,y_test = data.return_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "postal-marine",
      "metadata": {
        "scrolled": true,
        "id": "postal-marine",
        "outputId": "aea20e98-968b-471f-8b8d-1413e1dbf504"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[0;31mInit signature:\u001b[0m\n",
              "\u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mshrinking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
              "\u001b[0;31mDocstring:\u001b[0m     \n",
              "Epsilon-Support Vector Regression.\n",
              "\n",
              "The free parameters in the model are C and epsilon.\n",
              "\n",
              "The implementation is based on libsvm. The fit time complexity\n",
              "is more than quadratic with the number of samples which makes it hard\n",
              "to scale to datasets with more than a couple of 10000 samples. For large\n",
              "datasets consider using :class:`~sklearn.svm.LinearSVR` or\n",
              ":class:`~sklearn.linear_model.SGDRegressor` instead, possibly after a\n",
              ":class:`~sklearn.kernel_approximation.Nystroem` transformer.\n",
              "\n",
              "Read more in the :ref:`User Guide <svm_regression>`.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
              "     Specifies the kernel type to be used in the algorithm.\n",
              "     It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
              "     a callable.\n",
              "     If none is given, 'rbf' will be used. If a callable is given it is\n",
              "     used to precompute the kernel matrix.\n",
              "\n",
              "degree : int, default=3\n",
              "    Degree of the polynomial kernel function ('poly').\n",
              "    Ignored by all other kernels.\n",
              "\n",
              "gamma : {'scale', 'auto'} or float, default='scale'\n",
              "    Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
              "\n",
              "    - if ``gamma='scale'`` (default) is passed then it uses\n",
              "      1 / (n_features * X.var()) as value of gamma,\n",
              "    - if 'auto', uses 1 / n_features.\n",
              "\n",
              "    .. versionchanged:: 0.22\n",
              "       The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
              "\n",
              "coef0 : float, default=0.0\n",
              "    Independent term in kernel function.\n",
              "    It is only significant in 'poly' and 'sigmoid'.\n",
              "\n",
              "tol : float, default=1e-3\n",
              "    Tolerance for stopping criterion.\n",
              "\n",
              "C : float, default=1.0\n",
              "    Regularization parameter. The strength of the regularization is\n",
              "    inversely proportional to C. Must be strictly positive.\n",
              "    The penalty is a squared l2 penalty.\n",
              "\n",
              "epsilon : float, default=0.1\n",
              "     Epsilon in the epsilon-SVR model. It specifies the epsilon-tube\n",
              "     within which no penalty is associated in the training loss function\n",
              "     with points predicted within a distance epsilon from the actual\n",
              "     value.\n",
              "\n",
              "shrinking : bool, default=True\n",
              "    Whether to use the shrinking heuristic.\n",
              "    See the :ref:`User Guide <shrinking_svm>`.\n",
              "\n",
              "cache_size : float, default=200\n",
              "    Specify the size of the kernel cache (in MB).\n",
              "\n",
              "verbose : bool, default=False\n",
              "    Enable verbose output. Note that this setting takes advantage of a\n",
              "    per-process runtime setting in libsvm that, if enabled, may not work\n",
              "    properly in a multithreaded context.\n",
              "\n",
              "max_iter : int, default=-1\n",
              "    Hard limit on iterations within solver, or -1 for no limit.\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "class_weight_ : ndarray of shape (n_classes,)\n",
              "    Multipliers of parameter C for each class.\n",
              "    Computed based on the ``class_weight`` parameter.\n",
              "\n",
              "coef_ : ndarray of shape (1, n_features)\n",
              "    Weights assigned to the features (coefficients in the primal\n",
              "    problem). This is only available in the case of a linear kernel.\n",
              "\n",
              "    `coef_` is readonly property derived from `dual_coef_` and\n",
              "    `support_vectors_`.\n",
              "\n",
              "dual_coef_ : ndarray of shape (1, n_SV)\n",
              "    Coefficients of the support vector in the decision function.\n",
              "\n",
              "fit_status_ : int\n",
              "    0 if correctly fitted, 1 otherwise (will raise warning)\n",
              "\n",
              "intercept_ : ndarray of shape (1,)\n",
              "    Constants in decision function.\n",
              "\n",
              "n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
              "    Number of support vectors for each class.\n",
              "\n",
              "shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
              "    Array dimensions of training vector ``X``.\n",
              "\n",
              "support_ : ndarray of shape (n_SV,)\n",
              "    Indices of support vectors.\n",
              "\n",
              "support_vectors_ : ndarray of shape (n_SV, n_features)\n",
              "    Support vectors.\n",
              "\n",
              "Examples\n",
              "--------\n",
              ">>> from sklearn.svm import SVR\n",
              ">>> from sklearn.pipeline import make_pipeline\n",
              ">>> from sklearn.preprocessing import StandardScaler\n",
              ">>> import numpy as np\n",
              ">>> n_samples, n_features = 10, 5\n",
              ">>> rng = np.random.RandomState(0)\n",
              ">>> y = rng.randn(n_samples)\n",
              ">>> X = rng.randn(n_samples, n_features)\n",
              ">>> regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
              ">>> regr.fit(X, y)\n",
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('svr', SVR(epsilon=0.2))])\n",
              "\n",
              "See Also\n",
              "--------\n",
              "NuSVR : Support Vector Machine for regression implemented using libsvm\n",
              "    using a parameter to control the number of support vectors.\n",
              "\n",
              "LinearSVR : Scalable Linear Support Vector Machine for regression\n",
              "    implemented using liblinear.\n",
              "\n",
              "References\n",
              "----------\n",
              ".. [1] `LIBSVM: A Library for Support Vector Machines\n",
              "    <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
              "\n",
              ".. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
              "    machines and comparison to regularizedlikelihood methods.\"\n",
              "    <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
              "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py\n",
              "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
              "\u001b[0;31mSubclasses:\u001b[0m     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "?SVR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "immune-score",
      "metadata": {
        "id": "immune-score"
      },
      "source": [
        "#### Hyperparameter tuning: GridSearch\n",
        "- Around 60% accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "micro-consensus",
      "metadata": {
        "scrolled": true,
        "id": "micro-consensus",
        "outputId": "f4ce93bd-36c2-4980-b024-cc55932d4742"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[0;31mInit signature:\u001b[0m\n",
              "\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2*n_jobs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
              "\u001b[0;31mDocstring:\u001b[0m     \n",
              "Exhaustive search over specified parameter values for an estimator.\n",
              "\n",
              "Important members are fit, predict.\n",
              "\n",
              "GridSearchCV implements a \"fit\" and a \"score\" method.\n",
              "It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
              "\"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
              "implemented in the estimator used.\n",
              "\n",
              "The parameters of the estimator used to apply these methods are optimized\n",
              "by cross-validated grid-search over a parameter grid.\n",
              "\n",
              "Read more in the :ref:`User Guide <grid_search>`.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "estimator : estimator object.\n",
              "    This is assumed to implement the scikit-learn estimator interface.\n",
              "    Either estimator needs to provide a ``score`` function,\n",
              "    or ``scoring`` must be passed.\n",
              "\n",
              "param_grid : dict or list of dictionaries\n",
              "    Dictionary with parameters names (`str`) as keys and lists of\n",
              "    parameter settings to try as values, or a list of such\n",
              "    dictionaries, in which case the grids spanned by each dictionary\n",
              "    in the list are explored. This enables searching over any sequence\n",
              "    of parameter settings.\n",
              "\n",
              "scoring : str, callable, list/tuple or dict, default=None\n",
              "    A single str (see :ref:`scoring_parameter`) or a callable\n",
              "    (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
              "\n",
              "    For evaluating multiple metrics, either give a list of (unique) strings\n",
              "    or a dict with names as keys and callables as values.\n",
              "\n",
              "    NOTE that when using custom scorers, each scorer should return a single\n",
              "    value. Metric functions returning a list/array of values can be wrapped\n",
              "    into multiple scorers that return one value each.\n",
              "\n",
              "    See :ref:`multimetric_grid_search` for an example.\n",
              "\n",
              "    If None, the estimator's score method is used.\n",
              "\n",
              "n_jobs : int, default=None\n",
              "    Number of jobs to run in parallel.\n",
              "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
              "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
              "    for more details.\n",
              "\n",
              "    .. versionchanged:: v0.20\n",
              "       `n_jobs` default changed from 1 to None\n",
              "\n",
              "pre_dispatch : int, or str, default=n_jobs\n",
              "    Controls the number of jobs that get dispatched during parallel\n",
              "    execution. Reducing this number can be useful to avoid an\n",
              "    explosion of memory consumption when more jobs get dispatched\n",
              "    than CPUs can process. This parameter can be:\n",
              "\n",
              "        - None, in which case all the jobs are immediately\n",
              "          created and spawned. Use this for lightweight and\n",
              "          fast-running jobs, to avoid delays due to on-demand\n",
              "          spawning of the jobs\n",
              "\n",
              "        - An int, giving the exact number of total jobs that are\n",
              "          spawned\n",
              "\n",
              "        - A str, giving an expression as a function of n_jobs,\n",
              "          as in '2*n_jobs'\n",
              "\n",
              "cv : int, cross-validation generator or an iterable, default=None\n",
              "    Determines the cross-validation splitting strategy.\n",
              "    Possible inputs for cv are:\n",
              "\n",
              "    - None, to use the default 5-fold cross validation,\n",
              "    - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
              "    - :term:`CV splitter`,\n",
              "    - An iterable yielding (train, test) splits as arrays of indices.\n",
              "\n",
              "    For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
              "    either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
              "    other cases, :class:`KFold` is used.\n",
              "\n",
              "    Refer :ref:`User Guide <cross_validation>` for the various\n",
              "    cross-validation strategies that can be used here.\n",
              "\n",
              "    .. versionchanged:: 0.22\n",
              "        ``cv`` default value if None changed from 3-fold to 5-fold.\n",
              "\n",
              "refit : bool, str, or callable, default=True\n",
              "    Refit an estimator using the best found parameters on the whole\n",
              "    dataset.\n",
              "\n",
              "    For multiple metric evaluation, this needs to be a `str` denoting the\n",
              "    scorer that would be used to find the best parameters for refitting\n",
              "    the estimator at the end.\n",
              "\n",
              "    Where there are considerations other than maximum score in\n",
              "    choosing a best estimator, ``refit`` can be set to a function which\n",
              "    returns the selected ``best_index_`` given ``cv_results_``. In that\n",
              "    case, the ``best_estimator_`` and ``best_params_`` will be set\n",
              "    according to the returned ``best_index_`` while the ``best_score_``\n",
              "    attribute will not be available.\n",
              "\n",
              "    The refitted estimator is made available at the ``best_estimator_``\n",
              "    attribute and permits using ``predict`` directly on this\n",
              "    ``GridSearchCV`` instance.\n",
              "\n",
              "    Also for multiple metric evaluation, the attributes ``best_index_``,\n",
              "    ``best_score_`` and ``best_params_`` will only be available if\n",
              "    ``refit`` is set and all of them will be determined w.r.t this specific\n",
              "    scorer.\n",
              "\n",
              "    See ``scoring`` parameter to know more about multiple metric\n",
              "    evaluation.\n",
              "\n",
              "    .. versionchanged:: 0.20\n",
              "        Support for callable added.\n",
              "\n",
              "verbose : int\n",
              "    Controls the verbosity: the higher, the more messages.\n",
              "\n",
              "    - >1 : the computation time for each fold and parameter candidate is\n",
              "      displayed;\n",
              "    - >2 : the score is also displayed;\n",
              "    - >3 : the fold and candidate parameter indexes are also displayed\n",
              "      together with the starting time of the computation.\n",
              "\n",
              "error_score : 'raise' or numeric, default=np.nan\n",
              "    Value to assign to the score if an error occurs in estimator fitting.\n",
              "    If set to 'raise', the error is raised. If a numeric value is given,\n",
              "    FitFailedWarning is raised. This parameter does not affect the refit\n",
              "    step, which will always raise the error.\n",
              "\n",
              "return_train_score : bool, default=False\n",
              "    If ``False``, the ``cv_results_`` attribute will not include training\n",
              "    scores.\n",
              "    Computing training scores is used to get insights on how different\n",
              "    parameter settings impact the overfitting/underfitting trade-off.\n",
              "    However computing the scores on the training set can be computationally\n",
              "    expensive and is not strictly required to select the parameters that\n",
              "    yield the best generalization performance.\n",
              "\n",
              "    .. versionadded:: 0.19\n",
              "\n",
              "    .. versionchanged:: 0.21\n",
              "        Default value was changed from ``True`` to ``False``\n",
              "\n",
              "\n",
              "Examples\n",
              "--------\n",
              ">>> from sklearn import svm, datasets\n",
              ">>> from sklearn.model_selection import GridSearchCV\n",
              ">>> iris = datasets.load_iris()\n",
              ">>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
              ">>> svc = svm.SVC()\n",
              ">>> clf = GridSearchCV(svc, parameters)\n",
              ">>> clf.fit(iris.data, iris.target)\n",
              "GridSearchCV(estimator=SVC(),\n",
              "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
              ">>> sorted(clf.cv_results_.keys())\n",
              "['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
              " 'param_C', 'param_kernel', 'params',...\n",
              " 'rank_test_score', 'split0_test_score',...\n",
              " 'split2_test_score', ...\n",
              " 'std_fit_time', 'std_score_time', 'std_test_score']\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "cv_results_ : dict of numpy (masked) ndarrays\n",
              "    A dict with keys as column headers and values as columns, that can be\n",
              "    imported into a pandas ``DataFrame``.\n",
              "\n",
              "    For instance the below given table\n",
              "\n",
              "    +------------+-----------+------------+-----------------+---+---------+\n",
              "    |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
              "    +============+===========+============+=================+===+=========+\n",
              "    |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
              "    +------------+-----------+------------+-----------------+---+---------+\n",
              "    |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
              "    +------------+-----------+------------+-----------------+---+---------+\n",
              "    |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
              "    +------------+-----------+------------+-----------------+---+---------+\n",
              "    |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
              "    +------------+-----------+------------+-----------------+---+---------+\n",
              "\n",
              "    will be represented by a ``cv_results_`` dict of::\n",
              "\n",
              "        {\n",
              "        'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
              "                                     mask = [False False False False]...)\n",
              "        'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
              "                                    mask = [ True  True False False]...),\n",
              "        'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
              "                                     mask = [False False  True  True]...),\n",
              "        'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
              "        'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
              "        'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
              "        'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
              "        'rank_test_score'    : [2, 4, 3, 1],\n",
              "        'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
              "        'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
              "        'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
              "        'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
              "        'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
              "        'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
              "        'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
              "        'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
              "        'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
              "        }\n",
              "\n",
              "    NOTE\n",
              "\n",
              "    The key ``'params'`` is used to store a list of parameter\n",
              "    settings dicts for all the parameter candidates.\n",
              "\n",
              "    The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
              "    ``std_score_time`` are all in seconds.\n",
              "\n",
              "    For multi-metric evaluation, the scores for all the scorers are\n",
              "    available in the ``cv_results_`` dict at the keys ending with that\n",
              "    scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
              "    above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
              "\n",
              "best_estimator_ : estimator\n",
              "    Estimator that was chosen by the search, i.e. estimator\n",
              "    which gave highest score (or smallest loss if specified)\n",
              "    on the left out data. Not available if ``refit=False``.\n",
              "\n",
              "    See ``refit`` parameter for more information on allowed values.\n",
              "\n",
              "best_score_ : float\n",
              "    Mean cross-validated score of the best_estimator\n",
              "\n",
              "    For multi-metric evaluation, this is present only if ``refit`` is\n",
              "    specified.\n",
              "\n",
              "    This attribute is not available if ``refit`` is a function.\n",
              "\n",
              "best_params_ : dict\n",
              "    Parameter setting that gave the best results on the hold out data.\n",
              "\n",
              "    For multi-metric evaluation, this is present only if ``refit`` is\n",
              "    specified.\n",
              "\n",
              "best_index_ : int\n",
              "    The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
              "    candidate parameter setting.\n",
              "\n",
              "    The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
              "    the parameter setting for the best model, that gives the highest\n",
              "    mean score (``search.best_score_``).\n",
              "\n",
              "    For multi-metric evaluation, this is present only if ``refit`` is\n",
              "    specified.\n",
              "\n",
              "scorer_ : function or a dict\n",
              "    Scorer function used on the held out data to choose the best\n",
              "    parameters for the model.\n",
              "\n",
              "    For multi-metric evaluation, this attribute holds the validated\n",
              "    ``scoring`` dict which maps the scorer key to the scorer callable.\n",
              "\n",
              "n_splits_ : int\n",
              "    The number of cross-validation splits (folds/iterations).\n",
              "\n",
              "refit_time_ : float\n",
              "    Seconds used for refitting the best model on the whole dataset.\n",
              "\n",
              "    This is present only if ``refit`` is not False.\n",
              "\n",
              "    .. versionadded:: 0.20\n",
              "\n",
              "multimetric_ : bool\n",
              "    Whether or not the scorers compute several metrics.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "The parameters selected are those that maximize the score of the left out\n",
              "data, unless an explicit score is passed in which case it is used instead.\n",
              "\n",
              "If `n_jobs` was set to a value higher than one, the data is copied for each\n",
              "point in the grid (and not `n_jobs` times). This is done for efficiency\n",
              "reasons if individual jobs take very little time, but may raise errors if\n",
              "the dataset is large and not enough memory is available.  A workaround in\n",
              "this case is to set `pre_dispatch`. Then, the memory is copied only\n",
              "`pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
              "n_jobs`.\n",
              "\n",
              "See Also\n",
              "---------\n",
              "ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
              "train_test_split : Utility function to split the data into a development\n",
              "    set usable for fitting a GridSearchCV instance and an evaluation set\n",
              "    for its final evaluation.\n",
              "sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
              "    loss function.\n",
              "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\n",
              "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
              "\u001b[0;31mSubclasses:\u001b[0m     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "?GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "german-present",
      "metadata": {
        "scrolled": true,
        "id": "german-present",
        "outputId": "ba698db3-82f4-4a3e-b0e5-1993a7d10eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 30 candidates, totalling 60 fits\n",
            "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   3.8s\n",
            "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   3.8s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   5.9s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   6.2s\n",
            "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   7.7s\n",
            "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   7.8s\n",
            "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   3.7s\n",
            "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   3.7s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   6.1s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   5.9s\n",
            "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   8.9s\n",
            "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   8.7s\n",
            "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   3.8s\n",
            "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   3.8s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   5.8s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   5.7s\n",
            "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   9.4s\n",
            "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   9.5s\n",
            "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   3.7s\n",
            "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   3.7s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   6.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   6.0s\n",
            "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   7.6s\n",
            "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   7.8s\n",
            "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   3.7s\n",
            "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   3.7s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   6.2s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   5.9s\n",
            "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   8.7s\n",
            "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   8.7s\n",
            "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   4.0s\n",
            "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   3.9s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   5.7s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   5.7s\n",
            "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   9.5s\n",
            "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   9.4s\n",
            "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   3.7s\n",
            "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   3.7s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.8s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   6.1s\n",
            "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   7.6s\n",
            "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   8.0s\n",
            "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   3.8s\n",
            "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   3.7s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   5.9s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   5.8s\n",
            "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   8.7s\n",
            "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   8.7s\n",
            "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   4.2s\n",
            "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   4.1s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   5.7s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   5.7s\n",
            "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   9.4s\n",
            "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   9.4s\n",
            "[CV] END ................................C=10, kernel=linear; total time=   3.4s\n",
            "[CV] END ................................C=10, kernel=linear; total time=   3.4s\n",
            "[CV] END ...............................C=100, kernel=linear; total time=   3.4s\n",
            "[CV] END ...............................C=100, kernel=linear; total time=   3.4s\n",
            "[CV] END ..............................C=1000, kernel=linear; total time=   3.6s\n",
            "[CV] END ..............................C=1000, kernel=linear; total time=   3.5s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, estimator=SVR(max_iter=10000),\n",
              "             param_grid=[{'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1],\n",
              "                          'kernel': ['poly', 'rbf', 'sigmoid']},\n",
              "                         {'C': [10, 100, 1000], 'kernel': ['linear']}],\n",
              "             return_train_score=True, scoring='neg_mean_squared_error',\n",
              "             verbose=2)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "    'kernel': ['poly','rbf','sigmoid'],\n",
        "    'C': [0.1,1,10],\n",
        "    'gamma': [0.01,0.1,1]\n",
        "    },\n",
        "    {\n",
        "    'kernel': ['linear'],\n",
        "    'C': [10,100,1000]\n",
        "    },\n",
        "]\n",
        "\n",
        "algo = SVR(max_iter=10000)\n",
        "\n",
        "search = GridSearchCV(estimator=algo,\n",
        "                     param_grid=param_grid,cv=2,\n",
        "                     scoring='neg_mean_squared_error',\n",
        "                     return_train_score=True,verbose=2)\n",
        "search.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "modified-tsunami",
      "metadata": {
        "id": "modified-tsunami",
        "outputId": "7bb79d2f-bb0b-44ca-b4d9-56f49aca4e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5008386007.166459\n",
            "{'C': 1000, 'kernel': 'linear'}\n"
          ]
        }
      ],
      "source": [
        "print(-search.best_score_)\n",
        "print(search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "large-philosophy",
      "metadata": {
        "id": "large-philosophy",
        "outputId": "e971ee98-8e11-4b5f-ded3-79782ba8f18e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 0.6275142725036174\n",
            "Accuracy Test: 0.6008311206376373\n"
          ]
        }
      ],
      "source": [
        "algo = SVR(C=1000,kernel='linear')\n",
        "model = algo.fit(x_train,y_train)\n",
        "acc_train = model.score(x_train,y_train)\n",
        "acc_test = model.score(x_test,y_test)\n",
        "print(\"Accuracy Train: %s\" % acc_train)\n",
        "print(\"Accuracy Test: %s\" % acc_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "joined-village",
      "metadata": {
        "scrolled": true,
        "id": "joined-village",
        "outputId": "bea84d60-a9bb-4106-8087-f48be59bc8db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 7 candidates, totalling 14 fits\n",
            "[CV] END ..............................C=3000, kernel=linear; total time=   3.6s\n",
            "[CV] END ..............................C=3000, kernel=linear; total time=   3.6s\n",
            "[CV] END ..............................C=6000, kernel=linear; total time=   3.7s\n",
            "[CV] END ..............................C=6000, kernel=linear; total time=   3.7s\n",
            "[CV] END .............................C=10000, kernel=linear; total time=   3.8s\n",
            "[CV] END .............................C=10000, kernel=linear; total time=   3.8s\n",
            "[CV] END .............................C=12500, kernel=linear; total time=   3.8s\n",
            "[CV] END .............................C=12500, kernel=linear; total time=   3.9s\n",
            "[CV] END .............................C=15000, kernel=linear; total time=   4.0s\n",
            "[CV] END .............................C=15000, kernel=linear; total time=   4.0s\n",
            "[CV] END .............................C=17500, kernel=linear; total time=   4.0s\n",
            "[CV] END .............................C=17500, kernel=linear; total time=   4.0s\n",
            "[CV] END .............................C=20000, kernel=linear; total time=   4.1s\n",
            "[CV] END .............................C=20000, kernel=linear; total time=   4.2s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, estimator=SVR(max_iter=10000),\n",
              "             param_grid=[{'C': [3000, 6000, 10000, 12500, 15000, 17500, 20000],\n",
              "                          'kernel': ['linear']}],\n",
              "             return_train_score=True, scoring='neg_mean_squared_error',\n",
              "             verbose=2)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "    'kernel': ['linear'],\n",
        "    'C': [3000,6000,10000,12500,15000,17500,20000]\n",
        "    },\n",
        "]\n",
        "\n",
        "algo = SVR(max_iter=10000)\n",
        "\n",
        "search = GridSearchCV(estimator=algo,\n",
        "                     param_grid=param_grid,cv=2,\n",
        "                     scoring='neg_mean_squared_error',\n",
        "                     return_train_score=True,verbose=2)\n",
        "search.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "broken-heath",
      "metadata": {
        "id": "broken-heath",
        "outputId": "7fc788e2-c7e2-4b8f-db31-dc78204e3f8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4963970267.311083\n",
            "{'C': 10000, 'kernel': 'linear'}\n"
          ]
        }
      ],
      "source": [
        "print(-search.best_score_)\n",
        "print(search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "welcome-philosophy",
      "metadata": {
        "id": "welcome-philosophy",
        "outputId": "b925c28e-f3c7-40cd-d9ab-2ddeef9bcc6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 0.6287221721938374\n",
            "Accuracy Test: 0.5983949618746047\n"
          ]
        }
      ],
      "source": [
        "algo = SVR(C=10000,kernel='linear')\n",
        "model = algo.fit(x_train,y_train)\n",
        "acc_train = model.score(x_train,y_train)\n",
        "acc_test = model.score(x_test,y_test)\n",
        "print(\"Accuracy Train: %s\" % acc_train)\n",
        "print(\"Accuracy Test: %s\" % acc_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "committed-equality",
      "metadata": {
        "id": "committed-equality"
      },
      "source": [
        "#### Hyperparameter tuning: RandomizedSearchCV\n",
        "- Around 80% accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "periodic-bedroom",
      "metadata": {
        "scrolled": true,
        "id": "periodic-bedroom",
        "outputId": "6026fe92-d8a2-47f9-c470-947cc7ae6ca9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[0;31mInit signature:\u001b[0m\n",
              "\u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2*n_jobs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
              "\u001b[0;31mDocstring:\u001b[0m     \n",
              "Randomized search on hyper parameters.\n",
              "\n",
              "RandomizedSearchCV implements a \"fit\" and a \"score\" method.\n",
              "It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
              "\"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
              "implemented in the estimator used.\n",
              "\n",
              "The parameters of the estimator used to apply these methods are optimized\n",
              "by cross-validated search over parameter settings.\n",
              "\n",
              "In contrast to GridSearchCV, not all parameter values are tried out, but\n",
              "rather a fixed number of parameter settings is sampled from the specified\n",
              "distributions. The number of parameter settings that are tried is\n",
              "given by n_iter.\n",
              "\n",
              "If all parameters are presented as a list,\n",
              "sampling without replacement is performed. If at least one parameter\n",
              "is given as a distribution, sampling with replacement is used.\n",
              "It is highly recommended to use continuous distributions for continuous\n",
              "parameters.\n",
              "\n",
              "Read more in the :ref:`User Guide <randomized_parameter_search>`.\n",
              "\n",
              ".. versionadded:: 0.14\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "estimator : estimator object.\n",
              "    A object of that type is instantiated for each grid point.\n",
              "    This is assumed to implement the scikit-learn estimator interface.\n",
              "    Either estimator needs to provide a ``score`` function,\n",
              "    or ``scoring`` must be passed.\n",
              "\n",
              "param_distributions : dict or list of dicts\n",
              "    Dictionary with parameters names (`str`) as keys and distributions\n",
              "    or lists of parameters to try. Distributions must provide a ``rvs``\n",
              "    method for sampling (such as those from scipy.stats.distributions).\n",
              "    If a list is given, it is sampled uniformly.\n",
              "    If a list of dicts is given, first a dict is sampled uniformly, and\n",
              "    then a parameter is sampled using that dict as above.\n",
              "\n",
              "n_iter : int, default=10\n",
              "    Number of parameter settings that are sampled. n_iter trades\n",
              "    off runtime vs quality of the solution.\n",
              "\n",
              "scoring : str, callable, list/tuple or dict, default=None\n",
              "    A single str (see :ref:`scoring_parameter`) or a callable\n",
              "    (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
              "\n",
              "    For evaluating multiple metrics, either give a list of (unique) strings\n",
              "    or a dict with names as keys and callables as values.\n",
              "\n",
              "    NOTE that when using custom scorers, each scorer should return a single\n",
              "    value. Metric functions returning a list/array of values can be wrapped\n",
              "    into multiple scorers that return one value each.\n",
              "\n",
              "    See :ref:`multimetric_grid_search` for an example.\n",
              "\n",
              "    If None, the estimator's score method is used.\n",
              "\n",
              "n_jobs : int, default=None\n",
              "    Number of jobs to run in parallel.\n",
              "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
              "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
              "    for more details.\n",
              "\n",
              "    .. versionchanged:: v0.20\n",
              "       `n_jobs` default changed from 1 to None\n",
              "\n",
              "pre_dispatch : int, or str, default=None\n",
              "    Controls the number of jobs that get dispatched during parallel\n",
              "    execution. Reducing this number can be useful to avoid an\n",
              "    explosion of memory consumption when more jobs get dispatched\n",
              "    than CPUs can process. This parameter can be:\n",
              "\n",
              "        - None, in which case all the jobs are immediately\n",
              "          created and spawned. Use this for lightweight and\n",
              "          fast-running jobs, to avoid delays due to on-demand\n",
              "          spawning of the jobs\n",
              "\n",
              "        - An int, giving the exact number of total jobs that are\n",
              "          spawned\n",
              "\n",
              "        - A str, giving an expression as a function of n_jobs,\n",
              "          as in '2*n_jobs'\n",
              "\n",
              "cv : int, cross-validation generator or an iterable, default=None\n",
              "    Determines the cross-validation splitting strategy.\n",
              "    Possible inputs for cv are:\n",
              "\n",
              "    - None, to use the default 5-fold cross validation,\n",
              "    - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
              "    - :term:`CV splitter`,\n",
              "    - An iterable yielding (train, test) splits as arrays of indices.\n",
              "\n",
              "    For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
              "    either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
              "    other cases, :class:`KFold` is used.\n",
              "\n",
              "    Refer :ref:`User Guide <cross_validation>` for the various\n",
              "    cross-validation strategies that can be used here.\n",
              "\n",
              "    .. versionchanged:: 0.22\n",
              "        ``cv`` default value if None changed from 3-fold to 5-fold.\n",
              "\n",
              "refit : bool, str, or callable, default=True\n",
              "    Refit an estimator using the best found parameters on the whole\n",
              "    dataset.\n",
              "\n",
              "    For multiple metric evaluation, this needs to be a `str` denoting the\n",
              "    scorer that would be used to find the best parameters for refitting\n",
              "    the estimator at the end.\n",
              "\n",
              "    Where there are considerations other than maximum score in\n",
              "    choosing a best estimator, ``refit`` can be set to a function which\n",
              "    returns the selected ``best_index_`` given the ``cv_results``. In that\n",
              "    case, the ``best_estimator_`` and ``best_params_`` will be set\n",
              "    according to the returned ``best_index_`` while the ``best_score_``\n",
              "    attribute will not be available.\n",
              "\n",
              "    The refitted estimator is made available at the ``best_estimator_``\n",
              "    attribute and permits using ``predict`` directly on this\n",
              "    ``RandomizedSearchCV`` instance.\n",
              "\n",
              "    Also for multiple metric evaluation, the attributes ``best_index_``,\n",
              "    ``best_score_`` and ``best_params_`` will only be available if\n",
              "    ``refit`` is set and all of them will be determined w.r.t this specific\n",
              "    scorer.\n",
              "\n",
              "    See ``scoring`` parameter to know more about multiple metric\n",
              "    evaluation.\n",
              "\n",
              "    .. versionchanged:: 0.20\n",
              "        Support for callable added.\n",
              "\n",
              "verbose : int\n",
              "    Controls the verbosity: the higher, the more messages.\n",
              "\n",
              "random_state : int, RandomState instance or None, default=None\n",
              "    Pseudo random number generator state used for random uniform sampling\n",
              "    from lists of possible values instead of scipy.stats distributions.\n",
              "    Pass an int for reproducible output across multiple\n",
              "    function calls.\n",
              "    See :term:`Glossary <random_state>`.\n",
              "\n",
              "error_score : 'raise' or numeric, default=np.nan\n",
              "    Value to assign to the score if an error occurs in estimator fitting.\n",
              "    If set to 'raise', the error is raised. If a numeric value is given,\n",
              "    FitFailedWarning is raised. This parameter does not affect the refit\n",
              "    step, which will always raise the error.\n",
              "\n",
              "return_train_score : bool, default=False\n",
              "    If ``False``, the ``cv_results_`` attribute will not include training\n",
              "    scores.\n",
              "    Computing training scores is used to get insights on how different\n",
              "    parameter settings impact the overfitting/underfitting trade-off.\n",
              "    However computing the scores on the training set can be computationally\n",
              "    expensive and is not strictly required to select the parameters that\n",
              "    yield the best generalization performance.\n",
              "\n",
              "    .. versionadded:: 0.19\n",
              "\n",
              "    .. versionchanged:: 0.21\n",
              "        Default value was changed from ``True`` to ``False``\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "cv_results_ : dict of numpy (masked) ndarrays\n",
              "    A dict with keys as column headers and values as columns, that can be\n",
              "    imported into a pandas ``DataFrame``.\n",
              "\n",
              "    For instance the below given table\n",
              "\n",
              "    +--------------+-------------+-------------------+---+---------------+\n",
              "    | param_kernel | param_gamma | split0_test_score |...|rank_test_score|\n",
              "    +==============+=============+===================+===+===============+\n",
              "    |    'rbf'     |     0.1     |       0.80        |...|       1       |\n",
              "    +--------------+-------------+-------------------+---+---------------+\n",
              "    |    'rbf'     |     0.2     |       0.84        |...|       3       |\n",
              "    +--------------+-------------+-------------------+---+---------------+\n",
              "    |    'rbf'     |     0.3     |       0.70        |...|       2       |\n",
              "    +--------------+-------------+-------------------+---+---------------+\n",
              "\n",
              "    will be represented by a ``cv_results_`` dict of::\n",
              "\n",
              "        {\n",
              "        'param_kernel' : masked_array(data = ['rbf', 'rbf', 'rbf'],\n",
              "                                      mask = False),\n",
              "        'param_gamma'  : masked_array(data = [0.1 0.2 0.3], mask = False),\n",
              "        'split0_test_score'  : [0.80, 0.84, 0.70],\n",
              "        'split1_test_score'  : [0.82, 0.50, 0.70],\n",
              "        'mean_test_score'    : [0.81, 0.67, 0.70],\n",
              "        'std_test_score'     : [0.01, 0.24, 0.00],\n",
              "        'rank_test_score'    : [1, 3, 2],\n",
              "        'split0_train_score' : [0.80, 0.92, 0.70],\n",
              "        'split1_train_score' : [0.82, 0.55, 0.70],\n",
              "        'mean_train_score'   : [0.81, 0.74, 0.70],\n",
              "        'std_train_score'    : [0.01, 0.19, 0.00],\n",
              "        'mean_fit_time'      : [0.73, 0.63, 0.43],\n",
              "        'std_fit_time'       : [0.01, 0.02, 0.01],\n",
              "        'mean_score_time'    : [0.01, 0.06, 0.04],\n",
              "        'std_score_time'     : [0.00, 0.00, 0.00],\n",
              "        'params'             : [{'kernel' : 'rbf', 'gamma' : 0.1}, ...],\n",
              "        }\n",
              "\n",
              "    NOTE\n",
              "\n",
              "    The key ``'params'`` is used to store a list of parameter\n",
              "    settings dicts for all the parameter candidates.\n",
              "\n",
              "    The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
              "    ``std_score_time`` are all in seconds.\n",
              "\n",
              "    For multi-metric evaluation, the scores for all the scorers are\n",
              "    available in the ``cv_results_`` dict at the keys ending with that\n",
              "    scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
              "    above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
              "\n",
              "best_estimator_ : estimator\n",
              "    Estimator that was chosen by the search, i.e. estimator\n",
              "    which gave highest score (or smallest loss if specified)\n",
              "    on the left out data. Not available if ``refit=False``.\n",
              "\n",
              "    For multi-metric evaluation, this attribute is present only if\n",
              "    ``refit`` is specified.\n",
              "\n",
              "    See ``refit`` parameter for more information on allowed values.\n",
              "\n",
              "best_score_ : float\n",
              "    Mean cross-validated score of the best_estimator.\n",
              "\n",
              "    For multi-metric evaluation, this is not available if ``refit`` is\n",
              "    ``False``. See ``refit`` parameter for more information.\n",
              "\n",
              "    This attribute is not available if ``refit`` is a function.\n",
              "\n",
              "best_params_ : dict\n",
              "    Parameter setting that gave the best results on the hold out data.\n",
              "\n",
              "    For multi-metric evaluation, this is not available if ``refit`` is\n",
              "    ``False``. See ``refit`` parameter for more information.\n",
              "\n",
              "best_index_ : int\n",
              "    The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
              "    candidate parameter setting.\n",
              "\n",
              "    The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
              "    the parameter setting for the best model, that gives the highest\n",
              "    mean score (``search.best_score_``).\n",
              "\n",
              "    For multi-metric evaluation, this is not available if ``refit`` is\n",
              "    ``False``. See ``refit`` parameter for more information.\n",
              "\n",
              "scorer_ : function or a dict\n",
              "    Scorer function used on the held out data to choose the best\n",
              "    parameters for the model.\n",
              "\n",
              "    For multi-metric evaluation, this attribute holds the validated\n",
              "    ``scoring`` dict which maps the scorer key to the scorer callable.\n",
              "\n",
              "n_splits_ : int\n",
              "    The number of cross-validation splits (folds/iterations).\n",
              "\n",
              "refit_time_ : float\n",
              "    Seconds used for refitting the best model on the whole dataset.\n",
              "\n",
              "    This is present only if ``refit`` is not False.\n",
              "\n",
              "    .. versionadded:: 0.20\n",
              "\n",
              "multimetric_ : bool\n",
              "    Whether or not the scorers compute several metrics.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "The parameters selected are those that maximize the score of the held-out\n",
              "data, according to the scoring parameter.\n",
              "\n",
              "If `n_jobs` was set to a value higher than one, the data is copied for each\n",
              "parameter setting(and not `n_jobs` times). This is done for efficiency\n",
              "reasons if individual jobs take very little time, but may raise errors if\n",
              "the dataset is large and not enough memory is available.  A workaround in\n",
              "this case is to set `pre_dispatch`. Then, the memory is copied only\n",
              "`pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
              "n_jobs`.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "GridSearchCV : Does exhaustive search over a grid of parameters.\n",
              "ParameterSampler : A generator over parameter settings, constructed from\n",
              "    param_distributions.\n",
              "\n",
              "Examples\n",
              "--------\n",
              ">>> from sklearn.datasets import load_iris\n",
              ">>> from sklearn.linear_model import LogisticRegression\n",
              ">>> from sklearn.model_selection import RandomizedSearchCV\n",
              ">>> from scipy.stats import uniform\n",
              ">>> iris = load_iris()\n",
              ">>> logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
              "...                               random_state=0)\n",
              ">>> distributions = dict(C=uniform(loc=0, scale=4),\n",
              "...                      penalty=['l2', 'l1'])\n",
              ">>> clf = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
              ">>> search = clf.fit(iris.data, iris.target)\n",
              ">>> search.best_params_\n",
              "{'C': 2..., 'penalty': 'l1'}\n",
              "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\n",
              "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
              "\u001b[0;31mSubclasses:\u001b[0m     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "?RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "comfortable-netherlands",
      "metadata": {
        "scrolled": true,
        "id": "comfortable-netherlands",
        "outputId": "0ea5e8f7-c561-42f8-b956-2c7e9abb83ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
            "[CV] END C=3054.5593265747007, gamma=1.2998117726172989, kernel=rbf; total time=   6.1s\n",
            "[CV] END C=3054.5593265747007, gamma=1.2998117726172989, kernel=rbf; total time=   6.1s\n",
            "[CV] END C=100.56736081816628, gamma=1.537112260798591, kernel=rbf; total time=   6.1s\n",
            "[CV] END C=100.56736081816628, gamma=1.537112260798591, kernel=rbf; total time=   5.8s\n",
            "[CV] END C=1169.4977743425577, gamma=5.338643436864871, kernel=rbf; total time=   7.6s\n",
            "[CV] END C=1169.4977743425577, gamma=5.338643436864871, kernel=rbf; total time=   7.7s\n",
            "[CV] END C=16584.418536729187, gamma=1.7959317863326765, kernel=linear; total time=   4.0s\n",
            "[CV] END C=16584.418536729187, gamma=1.7959317863326765, kernel=linear; total time=   4.0s\n",
            "[CV] END C=3518.1985194197077, gamma=1.0597343403037787, kernel=linear; total time=   3.6s\n",
            "[CV] END C=3518.1985194197077, gamma=1.0597343403037787, kernel=linear; total time=   3.6s\n",
            "[CV] END C=2822.367292411449, gamma=0.02862542571328279, kernel=linear; total time=   3.5s\n",
            "[CV] END C=2822.367292411449, gamma=0.02862542571328279, kernel=linear; total time=   3.6s\n",
            "[CV] END C=5187.655884521959, gamma=2.2327218309745986, kernel=rbf; total time=   6.1s\n",
            "[CV] END C=5187.655884521959, gamma=2.2327218309745986, kernel=rbf; total time=   6.1s\n",
            "[CV] END C=1027.5600882916774, gamma=0.39707513918314735, kernel=linear; total time=   3.6s\n",
            "[CV] END C=1027.5600882916774, gamma=0.39707513918314735, kernel=linear; total time=   3.5s\n",
            "[CV] END C=851.0852224310142, gamma=0.2564049276809849, kernel=rbf; total time=   6.0s\n",
            "[CV] END C=851.0852224310142, gamma=0.2564049276809849, kernel=rbf; total time=   6.2s\n",
            "[CV] END C=2219.352640673065, gamma=1.4109898557590277, kernel=linear; total time=   3.6s\n",
            "[CV] END C=2219.352640673065, gamma=1.4109898557590277, kernel=linear; total time=   3.5s\n",
            "[CV] END C=8949.999023962479, gamma=2.4690407416621363, kernel=linear; total time=   3.9s\n",
            "[CV] END C=8949.999023962479, gamma=2.4690407416621363, kernel=linear; total time=   3.8s\n",
            "[CV] END C=102.75183729007362, gamma=0.39986284148870305, kernel=rbf; total time=   5.8s\n",
            "[CV] END C=102.75183729007362, gamma=0.39986284148870305, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=513.2274021620532, gamma=0.36894430089649716, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=513.2274021620532, gamma=0.36894430089649716, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=2958.143654549937, gamma=0.6902949741402596, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=2958.143654549937, gamma=0.6902949741402596, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=6252.674986939169, gamma=1.7548166705988157, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=6252.674986939169, gamma=1.7548166705988157, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=495.9759209621738, gamma=0.30761358251925996, kernel=linear; total time=   3.5s\n",
            "[CV] END C=495.9759209621738, gamma=0.30761358251925996, kernel=linear; total time=   3.5s\n",
            "[CV] END C=25324.80257410478, gamma=2.2921185422822865, kernel=rbf; total time=   6.4s\n",
            "[CV] END C=25324.80257410478, gamma=2.2921185422822865, kernel=rbf; total time=   6.4s\n",
            "[CV] END C=1206.8574040965073, gamma=1.1630117137961993, kernel=linear; total time=   3.5s\n",
            "[CV] END C=1206.8574040965073, gamma=1.1630117137961993, kernel=linear; total time=   3.5s\n",
            "[CV] END C=1469.7815264519668, gamma=1.3261547048957083, kernel=linear; total time=   3.5s\n",
            "[CV] END C=1469.7815264519668, gamma=1.3261547048957083, kernel=linear; total time=   3.5s\n",
            "[CV] END C=22126.05813426494, gamma=0.8357806763810717, kernel=rbf; total time=   6.3s\n",
            "[CV] END C=22126.05813426494, gamma=0.8357806763810717, kernel=rbf; total time=   6.0s\n",
            "[CV] END C=7502.630567867916, gamma=0.4308044495506451, kernel=rbf; total time=   5.7s\n",
            "[CV] END C=7502.630567867916, gamma=0.4308044495506451, kernel=rbf; total time=   5.8s\n",
            "[CV] END C=940.1107051829152, gamma=3.1766911630347527, kernel=rbf; total time=   6.4s\n",
            "[CV] END C=940.1107051829152, gamma=3.1766911630347527, kernel=rbf; total time=   6.4s\n",
            "[CV] END C=5164.796290032055, gamma=0.5175312967470923, kernel=rbf; total time=   5.7s\n",
            "[CV] END C=5164.796290032055, gamma=0.5175312967470923, kernel=rbf; total time=   5.8s\n",
            "[CV] END C=20976.048684416994, gamma=0.4659200108625905, kernel=rbf; total time=   5.8s\n",
            "[CV] END C=20976.048684416994, gamma=0.4659200108625905, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=11108.592516449717, gamma=0.07221117667952853, kernel=rbf; total time=   6.1s\n",
            "[CV] END C=11108.592516449717, gamma=0.07221117667952853, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=1597.195405349952, gamma=0.8110072677170922, kernel=rbf; total time=   6.1s\n",
            "[CV] END C=1597.195405349952, gamma=0.8110072677170922, kernel=rbf; total time=   5.7s\n",
            "[CV] END C=488.80961007888607, gamma=2.24183596484351, kernel=linear; total time=   3.5s\n",
            "[CV] END C=488.80961007888607, gamma=2.24183596484351, kernel=linear; total time=   3.4s\n",
            "[CV] END C=2013.4011756251957, gamma=1.957163900316158, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=2013.4011756251957, gamma=1.957163900316158, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=15097.465465427993, gamma=0.37382991183365133, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=15097.465465427993, gamma=0.37382991183365133, kernel=rbf; total time=   5.8s\n",
            "[CV] END C=63787.8142248369, gamma=1.0155610271452773, kernel=rbf; total time=   6.5s\n",
            "[CV] END C=63787.8142248369, gamma=1.0155610271452773, kernel=rbf; total time=   6.5s\n",
            "[CV] END C=953.2169172550965, gamma=3.1744614051232265, kernel=rbf; total time=   6.4s\n",
            "[CV] END C=953.2169172550965, gamma=3.1744614051232265, kernel=rbf; total time=   6.4s\n",
            "[CV] END C=161.37377545582964, gamma=0.6018981820692548, kernel=rbf; total time=   5.7s\n",
            "[CV] END C=161.37377545582964, gamma=0.6018981820692548, kernel=rbf; total time=   5.8s\n",
            "[CV] END C=3835.1876427688603, gamma=0.9310748894517911, kernel=rbf; total time=   6.1s\n",
            "[CV] END C=3835.1876427688603, gamma=0.9310748894517911, kernel=rbf; total time=   5.7s\n",
            "[CV] END C=410.88401215159865, gamma=0.09395228471324765, kernel=linear; total time=   3.5s\n",
            "[CV] END C=410.88401215159865, gamma=0.09395228471324765, kernel=linear; total time=   3.4s\n",
            "[CV] END C=6385.519040054886, gamma=2.359768825834991, kernel=rbf; total time=   6.1s\n",
            "[CV] END C=6385.519040054886, gamma=2.359768825834991, kernel=rbf; total time=   6.0s\n",
            "[CV] END C=24103.751443752903, gamma=0.887052631113023, kernel=linear; total time=   4.2s\n",
            "[CV] END C=24103.751443752903, gamma=0.887052631113023, kernel=linear; total time=   4.1s\n",
            "[CV] END C=27194.79464887167, gamma=0.29510505907288115, kernel=linear; total time=   4.1s\n",
            "[CV] END C=27194.79464887167, gamma=0.29510505907288115, kernel=linear; total time=   4.1s\n",
            "[CV] END C=6433.471971105874, gamma=0.9978387204633968, kernel=rbf; total time=   6.2s\n",
            "[CV] END C=6433.471971105874, gamma=0.9978387204633968, kernel=rbf; total time=   5.7s\n",
            "[CV] END C=1405.3354012337645, gamma=2.1563941941154994, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=1405.3354012337645, gamma=2.1563941941154994, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=1822.1590953942875, gamma=2.317884196325902, kernel=rbf; total time=   6.0s\n",
            "[CV] END C=1822.1590953942875, gamma=2.317884196325902, kernel=rbf; total time=   6.0s\n",
            "[CV] END C=8346.57368356421, gamma=0.834004855912891, kernel=linear; total time=   3.7s\n",
            "[CV] END C=8346.57368356421, gamma=0.834004855912891, kernel=linear; total time=   3.7s\n",
            "[CV] END C=144.03425278710645, gamma=1.9901581236379802, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=144.03425278710645, gamma=1.9901581236379802, kernel=rbf; total time=   5.9s\n",
            "[CV] END C=292.3070012521864, gamma=3.8290019627608016, kernel=linear; total time=   3.5s\n",
            "[CV] END C=292.3070012521864, gamma=3.8290019627608016, kernel=linear; total time=   3.4s\n",
            "[CV] END C=3895.797478853799, gamma=4.119651469303294, kernel=linear; total time=   3.6s\n",
            "[CV] END C=3895.797478853799, gamma=4.119651469303294, kernel=linear; total time=   3.6s\n",
            "[CV] END C=1027.1685209227887, gamma=1.7035182938490894, kernel=linear; total time=   3.5s\n",
            "[CV] END C=1027.1685209227887, gamma=1.7035182938490894, kernel=linear; total time=   3.5s\n",
            "[CV] END C=442.08413804203747, gamma=0.47221496252872575, kernel=linear; total time=   3.4s\n",
            "[CV] END C=442.08413804203747, gamma=0.47221496252872575, kernel=linear; total time=   3.4s\n",
            "[CV] END C=6011.862741201766, gamma=1.2549151634751838, kernel=linear; total time=   3.7s\n",
            "[CV] END C=6011.862741201766, gamma=1.2549151634751838, kernel=linear; total time=   3.7s\n",
            "[CV] END C=5414.648600674359, gamma=0.7391283713166594, kernel=linear; total time=   3.6s\n",
            "[CV] END C=5414.648600674359, gamma=0.7391283713166594, kernel=linear; total time=   3.6s\n",
            "[CV] END C=773.9438446409656, gamma=0.22270147129733653, kernel=rbf; total time=   5.7s\n",
            "[CV] END C=773.9438446409656, gamma=0.22270147129733653, kernel=rbf; total time=   5.7s\n",
            "[CV] END C=29300.335634398063, gamma=1.7231842475798755, kernel=rbf; total time=   6.3s\n",
            "[CV] END C=29300.335634398063, gamma=1.7231842475798755, kernel=rbf; total time=   6.2s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=2, estimator=SVR(max_iter=10000), n_iter=50,\n",
              "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1870301730>,\n",
              "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f18703012b0>,\n",
              "                                        'kernel': ['linear', 'rbf']},\n",
              "                   scoring='neg_mean_squared_error', verbose=2)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import expon,reciprocal\n",
        "\n",
        "param_dist = {\n",
        "    'kernel': ['linear','rbf'],\n",
        "    'C': reciprocal(100,100000),\n",
        "    'gamma':expon(scale=1.0),\n",
        "    }\n",
        "\n",
        "algo = SVR(max_iter=10000)\n",
        "search = RandomizedSearchCV(estimator=algo,\n",
        "                           param_distributions=param_dist,\n",
        "                           n_iter=50,cv=2,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           verbose=2)\n",
        "search.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "median-pizza",
      "metadata": {
        "id": "median-pizza",
        "outputId": "34518b7c-48eb-4571-b3b1-0d95e032c98c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3768753613.91717\n",
            "{'C': 63787.8142248369, 'gamma': 1.0155610271452773, 'kernel': 'rbf'}\n"
          ]
        }
      ],
      "source": [
        "print(-search.best_score_)\n",
        "print(search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "statewide-logan",
      "metadata": {
        "id": "statewide-logan",
        "outputId": "64190e05-3dad-4b72-cddf-a0b2c9df1262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 0.8166819196333613\n",
            "Accuracy Test: 0.7469916404922596\n"
          ]
        }
      ],
      "source": [
        "algo = SVR(C=63787.8142248369,gamma=1.0155610271452773,\n",
        "           kernel='rbf')\n",
        "model = algo.fit(x_train,y_train)\n",
        "acc_train = model.score(x_train,y_train)\n",
        "acc_test = model.score(x_test,y_test)\n",
        "print(\"Accuracy Train: %s\" % acc_train)\n",
        "print(\"Accuracy Test: %s\" % acc_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "turned-playback",
      "metadata": {
        "id": "turned-playback",
        "outputId": "3b4c0608-79f2-4f0d-8599-841c111013d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.7671563 , 0.74214522, 0.76335124, 0.74628767, 0.73544318,\n",
              "       0.75858437, 0.78165902, 0.7593132 , 0.73174801, 0.73858273])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#cross validation\n",
        "cv=10\n",
        "cross_val = cross_val_score(model,x_train,y_train,cv=cv)\n",
        "cross_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "second-reader",
      "metadata": {
        "id": "second-reader",
        "outputId": "df737b25-ea50-4297-b169-44d695755fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross val accuracy: 0.7524270941249671 \n",
            "Cross val stdev: 0.015255413640515162 \n"
          ]
        }
      ],
      "source": [
        "print('Cross val accuracy: %s ' % cross_val.mean())\n",
        "print('Cross val stdev: %s ' % cross_val.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "neutral-thousand",
      "metadata": {
        "id": "neutral-thousand",
        "outputId": "b7c245a7-3529-4291-dd82-1c4e9c16be56"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "plt.scatter(np.arange(0.1,1.1,0.1),cross_val)\n",
        "plt.ylim(0,1)\n",
        "plt.title('Cross validation accuracy',fontsize=25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "narrative-poverty",
      "metadata": {
        "id": "narrative-poverty"
      },
      "source": [
        "#### Hyperparameter tuning: Bayesian optimization\n",
        "- Around 80% accuracy with less overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bored-peoples",
      "metadata": {
        "scrolled": true,
        "id": "bored-peoples",
        "outputId": "ee6a06f0-b7a1-456a-dff4-a55014b79d9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[0;31mInit signature:\u001b[0m\n",
              "\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mshrinking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mdecision_function_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mbreak_ties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
              "\u001b[0;31mDocstring:\u001b[0m     \n",
              "C-Support Vector Classification.\n",
              "\n",
              "The implementation is based on libsvm. The fit time scales at least\n",
              "quadratically with the number of samples and may be impractical\n",
              "beyond tens of thousands of samples. For large datasets\n",
              "consider using :class:`~sklearn.svm.LinearSVC` or\n",
              ":class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
              ":class:`~sklearn.kernel_approximation.Nystroem` transformer.\n",
              "\n",
              "The multiclass support is handled according to a one-vs-one scheme.\n",
              "\n",
              "For details on the precise mathematical formulation of the provided\n",
              "kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
              "other, see the corresponding section in the narrative documentation:\n",
              ":ref:`svm_kernels`.\n",
              "\n",
              "Read more in the :ref:`User Guide <svm_classification>`.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "C : float, default=1.0\n",
              "    Regularization parameter. The strength of the regularization is\n",
              "    inversely proportional to C. Must be strictly positive. The penalty\n",
              "    is a squared l2 penalty.\n",
              "\n",
              "kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
              "    Specifies the kernel type to be used in the algorithm.\n",
              "    It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
              "    a callable.\n",
              "    If none is given, 'rbf' will be used. If a callable is given it is\n",
              "    used to pre-compute the kernel matrix from data matrices; that matrix\n",
              "    should be an array of shape ``(n_samples, n_samples)``.\n",
              "\n",
              "degree : int, default=3\n",
              "    Degree of the polynomial kernel function ('poly').\n",
              "    Ignored by all other kernels.\n",
              "\n",
              "gamma : {'scale', 'auto'} or float, default='scale'\n",
              "    Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
              "\n",
              "    - if ``gamma='scale'`` (default) is passed then it uses\n",
              "      1 / (n_features * X.var()) as value of gamma,\n",
              "    - if 'auto', uses 1 / n_features.\n",
              "\n",
              "    .. versionchanged:: 0.22\n",
              "       The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
              "\n",
              "coef0 : float, default=0.0\n",
              "    Independent term in kernel function.\n",
              "    It is only significant in 'poly' and 'sigmoid'.\n",
              "\n",
              "shrinking : bool, default=True\n",
              "    Whether to use the shrinking heuristic.\n",
              "    See the :ref:`User Guide <shrinking_svm>`.\n",
              "\n",
              "probability : bool, default=False\n",
              "    Whether to enable probability estimates. This must be enabled prior\n",
              "    to calling `fit`, will slow down that method as it internally uses\n",
              "    5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
              "    `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
              "\n",
              "tol : float, default=1e-3\n",
              "    Tolerance for stopping criterion.\n",
              "\n",
              "cache_size : float, default=200\n",
              "    Specify the size of the kernel cache (in MB).\n",
              "\n",
              "class_weight : dict or 'balanced', default=None\n",
              "    Set the parameter C of class i to class_weight[i]*C for\n",
              "    SVC. If not given, all classes are supposed to have\n",
              "    weight one.\n",
              "    The \"balanced\" mode uses the values of y to automatically adjust\n",
              "    weights inversely proportional to class frequencies in the input data\n",
              "    as ``n_samples / (n_classes * np.bincount(y))``\n",
              "\n",
              "verbose : bool, default=False\n",
              "    Enable verbose output. Note that this setting takes advantage of a\n",
              "    per-process runtime setting in libsvm that, if enabled, may not work\n",
              "    properly in a multithreaded context.\n",
              "\n",
              "max_iter : int, default=-1\n",
              "    Hard limit on iterations within solver, or -1 for no limit.\n",
              "\n",
              "decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
              "    Whether to return a one-vs-rest ('ovr') decision function of shape\n",
              "    (n_samples, n_classes) as all other classifiers, or the original\n",
              "    one-vs-one ('ovo') decision function of libsvm which has shape\n",
              "    (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
              "    ('ovo') is always used as multi-class strategy. The parameter is\n",
              "    ignored for binary classification.\n",
              "\n",
              "    .. versionchanged:: 0.19\n",
              "        decision_function_shape is 'ovr' by default.\n",
              "\n",
              "    .. versionadded:: 0.17\n",
              "       *decision_function_shape='ovr'* is recommended.\n",
              "\n",
              "    .. versionchanged:: 0.17\n",
              "       Deprecated *decision_function_shape='ovo' and None*.\n",
              "\n",
              "break_ties : bool, default=False\n",
              "    If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
              "    :term:`predict` will break ties according to the confidence values of\n",
              "    :term:`decision_function`; otherwise the first class among the tied\n",
              "    classes is returned. Please note that breaking ties comes at a\n",
              "    relatively high computational cost compared to a simple predict.\n",
              "\n",
              "    .. versionadded:: 0.22\n",
              "\n",
              "random_state : int, RandomState instance or None, default=None\n",
              "    Controls the pseudo random number generation for shuffling the data for\n",
              "    probability estimates. Ignored when `probability` is False.\n",
              "    Pass an int for reproducible output across multiple function calls.\n",
              "    See :term:`Glossary <random_state>`.\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "class_weight_ : ndarray of shape (n_classes,)\n",
              "    Multipliers of parameter C for each class.\n",
              "    Computed based on the ``class_weight`` parameter.\n",
              "\n",
              "classes_ : ndarray of shape (n_classes,)\n",
              "    The classes labels.\n",
              "\n",
              "coef_ : ndarray of shape (n_classes * (n_classes - 1) / 2, n_features)\n",
              "    Weights assigned to the features (coefficients in the primal\n",
              "    problem). This is only available in the case of a linear kernel.\n",
              "\n",
              "    `coef_` is a readonly property derived from `dual_coef_` and\n",
              "    `support_vectors_`.\n",
              "\n",
              "dual_coef_ : ndarray of shape (n_classes -1, n_SV)\n",
              "    Dual coefficients of the support vector in the decision\n",
              "    function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
              "    their targets.\n",
              "    For multiclass, coefficient for all 1-vs-1 classifiers.\n",
              "    The layout of the coefficients in the multiclass case is somewhat\n",
              "    non-trivial. See the :ref:`multi-class section of the User Guide\n",
              "    <svm_multi_class>` for details.\n",
              "\n",
              "fit_status_ : int\n",
              "    0 if correctly fitted, 1 otherwise (will raise warning)\n",
              "\n",
              "intercept_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n",
              "    Constants in decision function.\n",
              "\n",
              "support_ : ndarray of shape (n_SV)\n",
              "    Indices of support vectors.\n",
              "\n",
              "support_vectors_ : ndarray of shape (n_SV, n_features)\n",
              "    Support vectors.\n",
              "\n",
              "n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
              "    Number of support vectors for each class.\n",
              "\n",
              "probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
              "probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
              "    If `probability=True`, it corresponds to the parameters learned in\n",
              "    Platt scaling to produce probability estimates from decision values.\n",
              "    If `probability=False`, it's an empty array. Platt scaling uses the\n",
              "    logistic function\n",
              "    ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
              "    where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
              "    more information on the multiclass case and training procedure see\n",
              "    section 8 of [1]_.\n",
              "\n",
              "shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
              "    Array dimensions of training vector ``X``.\n",
              "\n",
              "Examples\n",
              "--------\n",
              ">>> import numpy as np\n",
              ">>> from sklearn.pipeline import make_pipeline\n",
              ">>> from sklearn.preprocessing import StandardScaler\n",
              ">>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
              ">>> y = np.array([1, 1, 2, 2])\n",
              ">>> from sklearn.svm import SVC\n",
              ">>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
              ">>> clf.fit(X, y)\n",
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('svc', SVC(gamma='auto'))])\n",
              "\n",
              ">>> print(clf.predict([[-0.8, -1]]))\n",
              "[1]\n",
              "\n",
              "See Also\n",
              "--------\n",
              "SVR : Support Vector Machine for Regression implemented using libsvm.\n",
              "\n",
              "LinearSVC : Scalable Linear Support Vector Machine for classification\n",
              "    implemented using liblinear. Check the See Also section of\n",
              "    LinearSVC for more comparison element.\n",
              "\n",
              "References\n",
              "----------\n",
              ".. [1] `LIBSVM: A Library for Support Vector Machines\n",
              "    <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
              "\n",
              ".. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
              "    machines and comparison to regularizedlikelihood methods.\"\n",
              "    <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
              "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py\n",
              "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
              "\u001b[0;31mSubclasses:\u001b[0m     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "?SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "casual-louis",
      "metadata": {
        "scrolled": true,
        "id": "casual-louis",
        "outputId": "bd3aa571-1762-4309-b507-a8b3b08290f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[0;31mSignature:\u001b[0m\n",
              "\u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9223372036854775807\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mloss_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mrstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mallow_trials_fmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mpoints_to_evaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mmax_queue_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mtrials_save_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
              "\u001b[0;31mDocstring:\u001b[0m\n",
              "Minimize a function over a hyperparameter space.\n",
              "\n",
              "More realistically: *explore* a function over a hyperparameter space\n",
              "according to a given algorithm, allowing up to a certain number of\n",
              "function evaluations.  As points are explored, they are accumulated in\n",
              "`trials`\n",
              "\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "\n",
              "fn : callable (trial point -> loss)\n",
              "    This function will be called with a value generated from `space`\n",
              "    as the first and possibly only argument.  It can return either\n",
              "    a scalar-valued loss, or a dictionary.  A returned dictionary must\n",
              "    contain a 'status' key with a value from `STATUS_STRINGS`, must\n",
              "    contain a 'loss' key if the status is `STATUS_OK`. Particular\n",
              "    optimization algorithms may look for other keys as well.  An\n",
              "    optional sub-dictionary associated with an 'attachments' key will\n",
              "    be removed by fmin its contents will be available via\n",
              "    `trials.trial_attachments`. The rest (usually all) of the returned\n",
              "    dictionary will be stored and available later as some 'result'\n",
              "    sub-dictionary within `trials.trials`.\n",
              "\n",
              "space : hyperopt.pyll.Apply node\n",
              "    The set of possible arguments to `fn` is the set of objects\n",
              "    that could be created with non-zero probability by drawing randomly\n",
              "    from this stochastic program involving involving hp_<xxx> nodes\n",
              "    (see `hyperopt.hp` and `hyperopt.pyll_utils`).\n",
              "\n",
              "algo : search algorithm\n",
              "    This object, such as `hyperopt.rand.suggest` and\n",
              "    `hyperopt.tpe.suggest` provides logic for sequential search of the\n",
              "    hyperparameter space.\n",
              "\n",
              "max_evals : int\n",
              "    Allow up to this many function evaluations before returning.\n",
              "\n",
              "timeout : None or int, default None\n",
              "    Limits search time by parametrized number of seconds.\n",
              "    If None, then the search process has no time constraint.\n",
              "\n",
              "loss_threshold : None or double, default None\n",
              "    Limits search time when minimal loss reduced to certain amount.\n",
              "    If None, then the search process has no constraint on the loss, \n",
              "    and will stop based on other parameters, e.g. `max_evals`, `timeout`\n",
              "\n",
              "trials : None or base.Trials (or subclass)\n",
              "    Storage for completed, ongoing, and scheduled evaluation points.  If\n",
              "    None, then a temporary `base.Trials` instance will be created.  If\n",
              "    a trials object, then that trials object will be affected by\n",
              "    side-effect of this call.\n",
              "\n",
              "rstate : numpy.RandomState, default numpy.random or `$HYPEROPT_FMIN_SEED`\n",
              "    Each call to `algo` requires a seed value, which should be different\n",
              "    on each call. This object is used to draw these seeds via `randint`.\n",
              "    The default rstate is\n",
              "    `numpy.random.RandomState(int(env['HYPEROPT_FMIN_SEED']))`\n",
              "    if the `HYPEROPT_FMIN_SEED` environment variable is set to a non-empty\n",
              "    string, otherwise np.random is used in whatever state it is in.\n",
              "\n",
              "verbose : bool\n",
              "    Print out some information to stdout during search. If False, disable\n",
              "        progress bar irrespectively of show_progressbar argument\n",
              "\n",
              "allow_trials_fmin : bool, default True\n",
              "    If the `trials` argument\n",
              "\n",
              "pass_expr_memo_ctrl : bool, default False\n",
              "    If set to True, `fn` will be called in a different more low-level\n",
              "    way: it will receive raw hyperparameters, a partially-populated\n",
              "    `memo`, and a Ctrl object for communication with this Trials\n",
              "    object.\n",
              "\n",
              "return_argmin : bool, default True\n",
              "    If set to False, this function returns nothing, which can be useful\n",
              "    for example if it is expected that `len(trials)` may be zero after\n",
              "    fmin, and therefore `trials.argmin` would be undefined.\n",
              "\n",
              "points_to_evaluate : list, default None\n",
              "    Only works if trials=None. If points_to_evaluate equals None then the\n",
              "    trials are evaluated normally. If list of dicts is passed then\n",
              "    given points are evaluated before optimisation starts, so the overall\n",
              "    number of optimisation steps is len(points_to_evaluate) + max_evals.\n",
              "    Elements of this list must be in a form of a dictionary with variable\n",
              "    names as keys and variable values as dict values. Example\n",
              "    points_to_evaluate value is [{'x': 0.0, 'y': 0.0}, {'x': 1.0, 'y': 2.0}]\n",
              "\n",
              "max_queue_len : integer, default 1\n",
              "    Sets the queue length generated in the dictionary or trials. Increasing this\n",
              "    value helps to slightly speed up parallel simulatulations which sometimes lag\n",
              "    on suggesting a new trial.\n",
              "\n",
              "show_progressbar : bool or context manager, default True (or False is verbose is False).\n",
              "    Show a progressbar. See `hyperopt.progress` for customizing progress reporting.\n",
              "\n",
              "early_stop_fn: callable ((result, *args) -> (Boolean, *args)).\n",
              "    Called after every run with the result of the run and the values returned by the function previously.\n",
              "    Stop the search if the function return true.\n",
              "    Default None.\n",
              "\n",
              "trials_save_file: str, default \"\"\n",
              "    Optional file name to save the trials object to every iteration.\n",
              "    If specified and the file already exists, will load from this file when\n",
              "    trials=None instead of creating a new base.Trials object\n",
              "\n",
              "Returns\n",
              "-------\n",
              "\n",
              "argmin : dictionary\n",
              "    If return_argmin is True returns `trials.argmin` which is a dictionary.  Otherwise\n",
              "    this function  returns the result of `hyperopt.space_eval(space, trails.argmin)` if there\n",
              "    were succesfull trails. This object shares the same structure as the space passed.\n",
              "    If there were no succesfull trails, it returns None.\n",
              "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.8/site-packages/hyperopt/fmin.py\n",
              "\u001b[0;31mType:\u001b[0m      function\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "?fmin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "interracial-williams",
      "metadata": {
        "id": "interracial-williams",
        "outputId": "8fbfa9f3-b1a6-4a25-c17b-3d8cc13dc209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|| 5/5 [03:14<00:00, 38.93s/trial, best loss: -0.7053669714462746]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'C': 79567.531640721, 'gamma': 2.00131184415237, 'kernel': 1}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
        "\n",
        "space = {'C': hp.uniform('C',100,100000),\n",
        "        'kernel':hp.choice('kernel',['linear','rbf']),\n",
        "        'gamma':hp.loguniform('gamma',0,1)\n",
        "        }\n",
        "def objective(space):\n",
        "\n",
        "    algo = SVR(max_iter=10000,C=space['C'],kernel=space['kernel'],gamma=space['gamma'])\n",
        "    accuracy = cross_val_score(algo,x_train,y_train,cv=5).mean()\n",
        "\n",
        "    return {'loss':-accuracy, 'status': STATUS_OK}\n",
        "\n",
        "best = fmin(fn=objective,space=space,algo=tpe.suggest,max_evals=5,trials=Trials())\n",
        "\n",
        "best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "improved-venture",
      "metadata": {
        "id": "improved-venture",
        "outputId": "01787c16-ad92-42a1-dee7-1a38a1687135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|| 50/50 [40:06<00:00, 48.12s/trial, best loss: -0.7716199843049507]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'C': 98444.24602802457, 'gamma': 0.33196206472681455, 'kernel': 1}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
        "\n",
        "space = {'C': hp.uniform('C',100,100000),\n",
        "        'kernel':hp.choice('kernel',['linear','rbf']),\n",
        "        'gamma':hp.lognormal('gamma',1,1)\n",
        "        }\n",
        "def objective(space):\n",
        "\n",
        "    algo = SVR(max_iter=10000,C=space['C'],kernel=space['kernel'],gamma=space['gamma'])\n",
        "    accuracy = cross_val_score(algo,x_train,y_train,cv=5).mean()\n",
        "\n",
        "    return {'loss':-accuracy, 'status': STATUS_OK}\n",
        "\n",
        "best = fmin(fn=objective,space=space,algo=tpe.suggest,max_evals=50,trials=Trials())\n",
        "\n",
        "best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "present-unknown",
      "metadata": {
        "id": "present-unknown",
        "outputId": "05160e27-52fd-4c8c-c784-a5b0df22ce56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 0.7999256499968933\n",
            "Accuracy Test: 0.7645044334143164\n"
          ]
        }
      ],
      "source": [
        "algo = SVR(C=98444.24602802457, gamma=0.33196206472681455,\n",
        "           kernel= 'rbf')\n",
        "model = algo.fit(x_train,y_train)\n",
        "\n",
        "acc_train = model.score(x_train,y_train)\n",
        "acc_test = model.score(x_test,y_test)\n",
        "print(\"Accuracy Train: %s\" % acc_train)\n",
        "print(\"Accuracy Test: %s\" % acc_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "classified-nelson",
      "metadata": {
        "id": "classified-nelson",
        "outputId": "101d0254-0bc2-49fe-edd6-f3bc57ea352c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.7849077 , 0.7616826 , 0.78518518, 0.76402603, 0.76305538,\n",
              "       0.78840109, 0.79493614, 0.77109326, 0.75888086, 0.75800354])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#cross validation\n",
        "cv=10\n",
        "cross_val = cross_val_score(model,x_train,y_train,cv=cv)\n",
        "cross_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hazardous-belize",
      "metadata": {
        "id": "hazardous-belize",
        "outputId": "6dd5b62d-bc79-4575-da97-0d071b5f331d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "plt.scatter(np.arange(0.1,1.1,0.1),cross_val)\n",
        "plt.ylim(0,1)\n",
        "plt.title('Cross validation accuracy',fontsize=25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unexpected-inspector",
      "metadata": {
        "id": "unexpected-inspector"
      },
      "source": [
        "#### Hyperparameter tuning: Genetic Algorithm\n",
        "- Above 80% accuracy but with a little overfiting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wireless-background",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "wireless-background",
        "outputId": "dd179966-9801-4705-913a-248200dfd96f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Optimization Progress:   0%|          | 0/42 [00:00<?, ?pipeline/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generation 1 - Current best internal CV score: -3502260445.4278345\n",
            "\n",
            "Generation 2 - Current best internal CV score: -3470268945.2336454\n",
            "\n",
            "Generation 3 - Current best internal CV score: -3470268945.2336454\n",
            "\n",
            "Generation 4 - Current best internal CV score: -3202547652.8204665\n",
            "\n",
            "Generation 5 - Current best internal CV score: -3202547652.8204665\n",
            "\n",
            "Best pipeline: SVR(input_matrix, C=96600.0, gamma=0.8560715796670523, kernel=rbf, max_iter=10000)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict={'sklearn.svm.SVR': {'C': array([   100.,    200.,    300.,    400.,    500.,    600.,    700.,\n",
              "          800.,    900.,   1000.,   1100.,   1200.,   1300.,   1400.,\n",
              "         1500.,   1600.,   1700.,   1800.,   1900.,   2000.,   2100.,\n",
              "         2200.,   2300.,   2400.,   2500.,   2600.,   2700.,   2800.,\n",
              "         2900.,   3000.,   3100.,   3200.,   3300.,   3400.,   3500.,\n",
              "         3600.,   3700.,   3800.,   3900.,   4000.,   4100.,   4200.,\n",
              "         4300.,   4400.,   4500.,   4600.,   4700.,   4800.,   4900.,\n",
              "         5000.,   5...\n",
              "       39.75909308,  6.82513372,  3.9507823 ,  1.68514599,  1.1611246 ,\n",
              "        1.22115512,  4.6217374 ,  6.00995042,  4.01530685,  3.24984483,\n",
              "        2.84451816,  4.60322   ,  0.53931696,  7.59399559, 17.41047082,\n",
              "        4.86205669,  1.30330474,  1.88900995,  4.75192932,  2.15037151]),\n",
              "                                                'kernel': ['rbf', 'linear'],\n",
              "                                                'max_iter': [10000]}},\n",
              "               early_stop=6, generations=5, offspring_size=6,\n",
              "               population_size=12, scoring='neg_mean_squared_error',\n",
              "               verbosity=2)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tpot import TPOTClassifier\n",
        "\n",
        "parameters = {\n",
        "    'max_iter':[10000],\n",
        "    'C':np.linspace(100,100000,1000),\n",
        "    'kernel':['rbf','linear'],\n",
        "    'gamma':np.random.lognormal(1,1,1000)\n",
        "}\n",
        "\n",
        "tpot_classifier = TPOTClassifier(generations=5,population_size=12,offspring_size=6,\n",
        "                                verbosity=2,early_stop=6,\n",
        "                                config_dict={'sklearn.svm.SVR':parameters},\n",
        "                                 cv=5,scoring='neg_mean_squared_error')\n",
        "tpot_classifier.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "local-recovery",
      "metadata": {
        "id": "local-recovery",
        "outputId": "f74cf3b8-79f6-4d9e-8ab8-689cb24486ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 0.8279207513609628\n",
            "Accuracy Test: 0.7580576091294122\n"
          ]
        }
      ],
      "source": [
        "algo = SVR(C=96600.0, gamma=0.8560715796670523,\n",
        "           kernel= 'rbf')\n",
        "model = algo.fit(x_train,y_train)\n",
        "\n",
        "acc_train = model.score(x_train,y_train)\n",
        "acc_test = model.score(x_test,y_test)\n",
        "print(\"Accuracy Train: %s\" % acc_train)\n",
        "print(\"Accuracy Test: %s\" % acc_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "clinical-snapshot",
      "metadata": {
        "id": "clinical-snapshot"
      },
      "source": [
        "#### Hyperparameter optimization: Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gross-offer",
      "metadata": {
        "scrolled": true,
        "id": "gross-offer",
        "outputId": "90533f00-c3f5-4bad-b162-af0dfb766e6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[0;31mInit signature:\u001b[0m\n",
              "\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mshrinking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mdecision_function_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mbreak_ties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
              "\u001b[0;31mDocstring:\u001b[0m     \n",
              "C-Support Vector Classification.\n",
              "\n",
              "The implementation is based on libsvm. The fit time scales at least\n",
              "quadratically with the number of samples and may be impractical\n",
              "beyond tens of thousands of samples. For large datasets\n",
              "consider using :class:`~sklearn.svm.LinearSVC` or\n",
              ":class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
              ":class:`~sklearn.kernel_approximation.Nystroem` transformer.\n",
              "\n",
              "The multiclass support is handled according to a one-vs-one scheme.\n",
              "\n",
              "For details on the precise mathematical formulation of the provided\n",
              "kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
              "other, see the corresponding section in the narrative documentation:\n",
              ":ref:`svm_kernels`.\n",
              "\n",
              "Read more in the :ref:`User Guide <svm_classification>`.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "C : float, default=1.0\n",
              "    Regularization parameter. The strength of the regularization is\n",
              "    inversely proportional to C. Must be strictly positive. The penalty\n",
              "    is a squared l2 penalty.\n",
              "\n",
              "kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
              "    Specifies the kernel type to be used in the algorithm.\n",
              "    It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
              "    a callable.\n",
              "    If none is given, 'rbf' will be used. If a callable is given it is\n",
              "    used to pre-compute the kernel matrix from data matrices; that matrix\n",
              "    should be an array of shape ``(n_samples, n_samples)``.\n",
              "\n",
              "degree : int, default=3\n",
              "    Degree of the polynomial kernel function ('poly').\n",
              "    Ignored by all other kernels.\n",
              "\n",
              "gamma : {'scale', 'auto'} or float, default='scale'\n",
              "    Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
              "\n",
              "    - if ``gamma='scale'`` (default) is passed then it uses\n",
              "      1 / (n_features * X.var()) as value of gamma,\n",
              "    - if 'auto', uses 1 / n_features.\n",
              "\n",
              "    .. versionchanged:: 0.22\n",
              "       The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
              "\n",
              "coef0 : float, default=0.0\n",
              "    Independent term in kernel function.\n",
              "    It is only significant in 'poly' and 'sigmoid'.\n",
              "\n",
              "shrinking : bool, default=True\n",
              "    Whether to use the shrinking heuristic.\n",
              "    See the :ref:`User Guide <shrinking_svm>`.\n",
              "\n",
              "probability : bool, default=False\n",
              "    Whether to enable probability estimates. This must be enabled prior\n",
              "    to calling `fit`, will slow down that method as it internally uses\n",
              "    5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
              "    `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
              "\n",
              "tol : float, default=1e-3\n",
              "    Tolerance for stopping criterion.\n",
              "\n",
              "cache_size : float, default=200\n",
              "    Specify the size of the kernel cache (in MB).\n",
              "\n",
              "class_weight : dict or 'balanced', default=None\n",
              "    Set the parameter C of class i to class_weight[i]*C for\n",
              "    SVC. If not given, all classes are supposed to have\n",
              "    weight one.\n",
              "    The \"balanced\" mode uses the values of y to automatically adjust\n",
              "    weights inversely proportional to class frequencies in the input data\n",
              "    as ``n_samples / (n_classes * np.bincount(y))``\n",
              "\n",
              "verbose : bool, default=False\n",
              "    Enable verbose output. Note that this setting takes advantage of a\n",
              "    per-process runtime setting in libsvm that, if enabled, may not work\n",
              "    properly in a multithreaded context.\n",
              "\n",
              "max_iter : int, default=-1\n",
              "    Hard limit on iterations within solver, or -1 for no limit.\n",
              "\n",
              "decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
              "    Whether to return a one-vs-rest ('ovr') decision function of shape\n",
              "    (n_samples, n_classes) as all other classifiers, or the original\n",
              "    one-vs-one ('ovo') decision function of libsvm which has shape\n",
              "    (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
              "    ('ovo') is always used as multi-class strategy. The parameter is\n",
              "    ignored for binary classification.\n",
              "\n",
              "    .. versionchanged:: 0.19\n",
              "        decision_function_shape is 'ovr' by default.\n",
              "\n",
              "    .. versionadded:: 0.17\n",
              "       *decision_function_shape='ovr'* is recommended.\n",
              "\n",
              "    .. versionchanged:: 0.17\n",
              "       Deprecated *decision_function_shape='ovo' and None*.\n",
              "\n",
              "break_ties : bool, default=False\n",
              "    If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
              "    :term:`predict` will break ties according to the confidence values of\n",
              "    :term:`decision_function`; otherwise the first class among the tied\n",
              "    classes is returned. Please note that breaking ties comes at a\n",
              "    relatively high computational cost compared to a simple predict.\n",
              "\n",
              "    .. versionadded:: 0.22\n",
              "\n",
              "random_state : int, RandomState instance or None, default=None\n",
              "    Controls the pseudo random number generation for shuffling the data for\n",
              "    probability estimates. Ignored when `probability` is False.\n",
              "    Pass an int for reproducible output across multiple function calls.\n",
              "    See :term:`Glossary <random_state>`.\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "class_weight_ : ndarray of shape (n_classes,)\n",
              "    Multipliers of parameter C for each class.\n",
              "    Computed based on the ``class_weight`` parameter.\n",
              "\n",
              "classes_ : ndarray of shape (n_classes,)\n",
              "    The classes labels.\n",
              "\n",
              "coef_ : ndarray of shape (n_classes * (n_classes - 1) / 2, n_features)\n",
              "    Weights assigned to the features (coefficients in the primal\n",
              "    problem). This is only available in the case of a linear kernel.\n",
              "\n",
              "    `coef_` is a readonly property derived from `dual_coef_` and\n",
              "    `support_vectors_`.\n",
              "\n",
              "dual_coef_ : ndarray of shape (n_classes -1, n_SV)\n",
              "    Dual coefficients of the support vector in the decision\n",
              "    function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
              "    their targets.\n",
              "    For multiclass, coefficient for all 1-vs-1 classifiers.\n",
              "    The layout of the coefficients in the multiclass case is somewhat\n",
              "    non-trivial. See the :ref:`multi-class section of the User Guide\n",
              "    <svm_multi_class>` for details.\n",
              "\n",
              "fit_status_ : int\n",
              "    0 if correctly fitted, 1 otherwise (will raise warning)\n",
              "\n",
              "intercept_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n",
              "    Constants in decision function.\n",
              "\n",
              "support_ : ndarray of shape (n_SV)\n",
              "    Indices of support vectors.\n",
              "\n",
              "support_vectors_ : ndarray of shape (n_SV, n_features)\n",
              "    Support vectors.\n",
              "\n",
              "n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
              "    Number of support vectors for each class.\n",
              "\n",
              "probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
              "probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
              "    If `probability=True`, it corresponds to the parameters learned in\n",
              "    Platt scaling to produce probability estimates from decision values.\n",
              "    If `probability=False`, it's an empty array. Platt scaling uses the\n",
              "    logistic function\n",
              "    ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
              "    where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
              "    more information on the multiclass case and training procedure see\n",
              "    section 8 of [1]_.\n",
              "\n",
              "shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
              "    Array dimensions of training vector ``X``.\n",
              "\n",
              "Examples\n",
              "--------\n",
              ">>> import numpy as np\n",
              ">>> from sklearn.pipeline import make_pipeline\n",
              ">>> from sklearn.preprocessing import StandardScaler\n",
              ">>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
              ">>> y = np.array([1, 1, 2, 2])\n",
              ">>> from sklearn.svm import SVC\n",
              ">>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
              ">>> clf.fit(X, y)\n",
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('svc', SVC(gamma='auto'))])\n",
              "\n",
              ">>> print(clf.predict([[-0.8, -1]]))\n",
              "[1]\n",
              "\n",
              "See Also\n",
              "--------\n",
              "SVR : Support Vector Machine for Regression implemented using libsvm.\n",
              "\n",
              "LinearSVC : Scalable Linear Support Vector Machine for classification\n",
              "    implemented using liblinear. Check the See Also section of\n",
              "    LinearSVC for more comparison element.\n",
              "\n",
              "References\n",
              "----------\n",
              ".. [1] `LIBSVM: A Library for Support Vector Machines\n",
              "    <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
              "\n",
              ".. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
              "    machines and comparison to regularizedlikelihood methods.\"\n",
              "    <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
              "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py\n",
              "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
              "\u001b[0;31mSubclasses:\u001b[0m     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "?SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "incomplete-circus",
      "metadata": {
        "scrolled": true,
        "id": "incomplete-circus",
        "outputId": "057eba3a-9df2-4a6f-d0de-087050dbf20a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-21 18:50:22,011]\u001b[0m A new study created in memory with name: no-name-02e5b866-ba74-41fc-b1ef-99ccaf3da796\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 18:51:19,304]\u001b[0m Trial 0 finished with value: 0.7022894699456583 and parameters: {'C': 15564.442233245914, 'kernel': 'rbf', 'gamma': 0.04041404641101669}. Best is trial 0 with value: 0.7022894699456583.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 18:52:03,711]\u001b[0m Trial 1 finished with value: 0.6221912931747645 and parameters: {'C': 16244.623283269073, 'kernel': 'linear', 'gamma': 0.17426567000036886}. Best is trial 0 with value: 0.7022894699456583.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 18:53:02,664]\u001b[0m Trial 2 finished with value: 0.5967769338853077 and parameters: {'C': 1600.9413341443908, 'kernel': 'rbf', 'gamma': 0.23530985160468734}. Best is trial 0 with value: 0.7022894699456583.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 18:53:47,133]\u001b[0m Trial 3 finished with value: 0.6042452616207409 and parameters: {'C': 22358.92986036869, 'kernel': 'linear', 'gamma': 0.035248688985097414}. Best is trial 0 with value: 0.7022894699456583.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 18:54:44,254]\u001b[0m Trial 4 finished with value: 0.7172994728288876 and parameters: {'C': 29464.587254348316, 'kernel': 'rbf', 'gamma': 0.04842717417945678}. Best is trial 4 with value: 0.7172994728288876.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 18:55:46,968]\u001b[0m Trial 5 finished with value: 0.7360491864868971 and parameters: {'C': 74848.458058852, 'kernel': 'rbf', 'gamma': 1.3566888467760458}. Best is trial 5 with value: 0.7360491864868971.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 18:56:31,956]\u001b[0m Trial 6 finished with value: 0.6016371564395815 and parameters: {'C': 21663.188201492638, 'kernel': 'linear', 'gamma': 0.05729016045843048}. Best is trial 5 with value: 0.7360491864868971.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 18:57:16,658]\u001b[0m Trial 7 finished with value: 0.6198053068099593 and parameters: {'C': 19537.524171306082, 'kernel': 'linear', 'gamma': 0.2187747582548267}. Best is trial 5 with value: 0.7360491864868971.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 18:58:01,521]\u001b[0m Trial 8 finished with value: 0.6250522041952132 and parameters: {'C': 13018.0090516762, 'kernel': 'linear', 'gamma': 1.888738167310812}. Best is trial 5 with value: 0.7360491864868971.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 18:58:41,586]\u001b[0m Trial 9 finished with value: 0.4814459383765204 and parameters: {'C': 81655.4691750664, 'kernel': 'linear', 'gamma': 8.352382783795298}. Best is trial 5 with value: 0.7360491864868971.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 18:59:49,882]\u001b[0m Trial 10 finished with value: 0.7085432489302932 and parameters: {'C': 87730.72683434478, 'kernel': 'rbf', 'gamma': 2.0120880482843875}. Best is trial 5 with value: 0.7360491864868971.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:00:50,195]\u001b[0m Trial 11 finished with value: 0.6825154672653403 and parameters: {'C': 55809.63530097138, 'kernel': 'rbf', 'gamma': 0.01084989065419575}. Best is trial 5 with value: 0.7360491864868971.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:01:50,806]\u001b[0m Trial 12 finished with value: 0.7361363084608487 and parameters: {'C': 50600.63786172535, 'kernel': 'rbf', 'gamma': 1.097023127504037}. Best is trial 12 with value: 0.7361363084608487.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:02:51,210]\u001b[0m Trial 13 finished with value: 0.7393700226327945 and parameters: {'C': 65471.36467842968, 'kernel': 'rbf', 'gamma': 1.2065322483480505}. Best is trial 13 with value: 0.7393700226327945.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:03:50,505]\u001b[0m Trial 14 finished with value: 0.7521878471909567 and parameters: {'C': 55530.68600912115, 'kernel': 'rbf', 'gamma': 0.8021954347131417}. Best is trial 14 with value: 0.7521878471909567.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:05:39,902]\u001b[0m Trial 15 finished with value: 0.5045650851738122 and parameters: {'C': 68731.08517294652, 'kernel': 'rbf', 'gamma': 6.08290707942377}. Best is trial 14 with value: 0.7521878471909567.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:06:41,951]\u001b[0m Trial 16 finished with value: 0.7665430065838013 and parameters: {'C': 99531.28784499168, 'kernel': 'rbf', 'gamma': 0.668039256740237}. Best is trial 16 with value: 0.7665430065838013.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:07:44,083]\u001b[0m Trial 17 finished with value: 0.7693066761672659 and parameters: {'C': 94496.34807933157, 'kernel': 'rbf', 'gamma': 0.5191999684845541}. Best is trial 17 with value: 0.7693066761672659.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:08:42,996]\u001b[0m Trial 18 finished with value: 0.7704252807940564 and parameters: {'C': 99672.90305139557, 'kernel': 'rbf', 'gamma': 0.495176967227133}. Best is trial 18 with value: 0.7704252807940564.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:09:41,601]\u001b[0m Trial 19 finished with value: 0.7710262988468576 and parameters: {'C': 96974.8740070898, 'kernel': 'rbf', 'gamma': 0.4296093914107984}. Best is trial 19 with value: 0.7710262988468576.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:10:41,218]\u001b[0m Trial 20 finished with value: 0.7503336748497463 and parameters: {'C': 99129.65518138377, 'kernel': 'rbf', 'gamma': 0.10114574753594123}. Best is trial 19 with value: 0.7710262988468576.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:11:40,452]\u001b[0m Trial 21 finished with value: 0.7699131117643934 and parameters: {'C': 91787.00324694422, 'kernel': 'rbf', 'gamma': 0.45141222271647957}. Best is trial 19 with value: 0.7710262988468576.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:12:39,581]\u001b[0m Trial 22 finished with value: 0.7705089835839318 and parameters: {'C': 91460.74357184819, 'kernel': 'rbf', 'gamma': 0.35920571721664746}. Best is trial 19 with value: 0.7710262988468576.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:13:59,551]\u001b[0m Trial 23 finished with value: 0.6340606323781798 and parameters: {'C': 84488.23292072507, 'kernel': 'rbf', 'gamma': 3.5431577815814213}. Best is trial 19 with value: 0.7710262988468576.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:14:58,828]\u001b[0m Trial 24 finished with value: 0.7715880749042172 and parameters: {'C': 99448.59278046171, 'kernel': 'rbf', 'gamma': 0.34392791061008}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:15:57,975]\u001b[0m Trial 25 finished with value: 0.7501659736639124 and parameters: {'C': 77613.20916251444, 'kernel': 'rbf', 'gamma': 0.11214124220370783}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:16:56,726]\u001b[0m Trial 26 finished with value: 0.7705395775706241 and parameters: {'C': 90911.811435857, 'kernel': 'rbf', 'gamma': 0.3744016292724883}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:17:54,528]\u001b[0m Trial 27 finished with value: 0.7459942735045921 and parameters: {'C': 38242.939944295365, 'kernel': 'rbf', 'gamma': 0.1443029493613479}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:18:53,765]\u001b[0m Trial 28 finished with value: 0.7641579758507747 and parameters: {'C': 66466.08284899767, 'kernel': 'rbf', 'gamma': 0.24456459845105538}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:19:54,853]\u001b[0m Trial 29 finished with value: 0.742510568627021 and parameters: {'C': 96883.17508364818, 'kernel': 'rbf', 'gamma': 0.07415988146025217}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:20:54,145]\u001b[0m Trial 30 finished with value: 0.7195046657871116 and parameters: {'C': 75107.62839923684, 'kernel': 'rbf', 'gamma': 0.030375777233502647}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:21:53,717]\u001b[0m Trial 31 finished with value: 0.770677483623969 and parameters: {'C': 90516.7495949891, 'kernel': 'rbf', 'gamma': 0.358647190601623}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:22:54,198]\u001b[0m Trial 32 finished with value: 0.7699985727967151 and parameters: {'C': 85664.13824525724, 'kernel': 'rbf', 'gamma': 0.35105583967141923}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:23:56,767]\u001b[0m Trial 33 finished with value: 0.7637565067078043 and parameters: {'C': 91329.10926509787, 'kernel': 'rbf', 'gamma': 0.7485159813471497}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:24:59,812]\u001b[0m Trial 34 finished with value: 0.7604088547648832 and parameters: {'C': 80573.53902127336, 'kernel': 'rbf', 'gamma': 0.1687600552917998}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:26:02,751]\u001b[0m Trial 35 finished with value: 0.7691566633679235 and parameters: {'C': 98550.4875405926, 'kernel': 'rbf', 'gamma': 0.2554518515375763}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:27:05,245]\u001b[0m Trial 36 finished with value: 0.7698711200539321 and parameters: {'C': 87659.14285961638, 'kernel': 'rbf', 'gamma': 0.3243862436108449}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:28:08,075]\u001b[0m Trial 37 finished with value: 0.7554901032747234 and parameters: {'C': 72220.54252014124, 'kernel': 'rbf', 'gamma': 0.14492380415749243}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:28:47,389]\u001b[0m Trial 38 finished with value: 0.3827720846642415 and parameters: {'C': 94374.23773982961, 'kernel': 'linear', 'gamma': 0.8457553622228196}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:29:45,797]\u001b[0m Trial 39 finished with value: 0.5934507691821329 and parameters: {'C': 3136.8706301828497, 'kernel': 'rbf', 'gamma': 0.511568798307484}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:30:48,463]\u001b[0m Trial 40 finished with value: 0.6715946576332433 and parameters: {'C': 37875.839853390855, 'kernel': 'rbf', 'gamma': 1.8722600201149207}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:31:47,536]\u001b[0m Trial 41 finished with value: 0.7704989387404548 and parameters: {'C': 90020.34148427931, 'kernel': 'rbf', 'gamma': 0.3407850415595212}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:32:47,091]\u001b[0m Trial 42 finished with value: 0.7648750110444028 and parameters: {'C': 82083.85306955932, 'kernel': 'rbf', 'gamma': 0.21249365621478708}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:33:49,517]\u001b[0m Trial 43 finished with value: 0.7706481600382575 and parameters: {'C': 94228.24139196923, 'kernel': 'rbf', 'gamma': 0.35198939658057027}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:34:28,735]\u001b[0m Trial 44 finished with value: 0.28227102249275193 and parameters: {'C': 96107.20755805176, 'kernel': 'linear', 'gamma': 0.5781082872702497}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:35:31,808]\u001b[0m Trial 45 finished with value: 0.7525391675917339 and parameters: {'C': 79176.67725247328, 'kernel': 'rbf', 'gamma': 1.0199969121764705}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:36:34,336]\u001b[0m Trial 46 finished with value: 0.7681989796342537 and parameters: {'C': 86367.66310267047, 'kernel': 'rbf', 'gamma': 0.26807525812182226}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:37:36,400]\u001b[0m Trial 47 finished with value: 0.7660001659307665 and parameters: {'C': 62049.69209143281, 'kernel': 'rbf', 'gamma': 0.4005806524307169}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:38:15,595]\u001b[0m Trial 48 finished with value: 0.36349388676159217 and parameters: {'C': 93726.2673475706, 'kernel': 'linear', 'gamma': 0.10330881214696987}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n",
            "\u001b[32m[I 2021-02-21 19:39:19,828]\u001b[0m Trial 49 finished with value: 0.7376060337960956 and parameters: {'C': 99443.83895617606, 'kernel': 'rbf', 'gamma': 1.4820474252694986}. Best is trial 24 with value: 0.7715880749042172.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    params = {\n",
        "        'C' : trial.suggest_uniform('C',1e2,1e5),\n",
        "        'kernel' : trial.suggest_categorical('kernel',['linear','rbf']),\n",
        "        'gamma' : trial.suggest_loguniform('gamma',1e-2,10)\n",
        "    }\n",
        "\n",
        "    model = SVR(**params,max_iter=1e4)\n",
        "    model.fit(x_train,y_train)\n",
        "\n",
        "    return cross_val_score(model,x_train,y_train,cv=5).mean()\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "continental-plaintiff",
      "metadata": {
        "id": "continental-plaintiff",
        "outputId": "3f958996-623e-4711-917e-c478e5e583e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 0.8010583464610941\n",
            "Accuracy Test: 0.7648248854107087\n"
          ]
        }
      ],
      "source": [
        "params = {'C': 99448.59278046171, 'kernel': 'rbf', 'gamma': 0.34392791061008}\n",
        "model = SVR(**params)\n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "acc_train = model.score(x_train,y_train)\n",
        "acc_test = model.score(x_test,y_test)\n",
        "print(\"Accuracy Train: %s\" % acc_train)\n",
        "print(\"Accuracy Test: %s\" % acc_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "voluntary-petite",
      "metadata": {
        "id": "voluntary-petite",
        "outputId": "a4b76d15-684f-4f71-bfd3-28925efec026"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.78516478, 0.7619253 , 0.78528563, 0.76412488, 0.76305053,\n",
              "       0.7882468 , 0.79525997, 0.77121953, 0.75911128, 0.75833689])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#cross validation\n",
        "cv=10\n",
        "cross_val = cross_val_score(model,x_train,y_train,cv=cv)\n",
        "cross_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "asian-rebound",
      "metadata": {
        "id": "asian-rebound",
        "outputId": "350a38f7-737a-4fa9-e1d0-919c8e9a8ef9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "plt.scatter(np.arange(0.1,1.1,0.1),cross_val)\n",
        "plt.ylim(0,1)\n",
        "plt.title('Cross validation accuracy',fontsize=25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "short-anthony",
      "metadata": {
        "id": "short-anthony"
      },
      "source": [
        "#### Save best model found and get predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "voluntary-analyst",
      "metadata": {
        "id": "voluntary-analyst",
        "outputId": "256f6387-909a-4212-9221-1964a72f272b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 0.8010583464610941\n",
            "Accuracy Test: 0.7648248854107087\n"
          ]
        }
      ],
      "source": [
        "params = {'C': 99448.59278046171, 'kernel': 'rbf', 'gamma': 0.34392791061008}\n",
        "model = SVR(**params)\n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "acc_train = model.score(x_train,y_train)\n",
        "acc_test = model.score(x_test,y_test)\n",
        "print(\"Accuracy Train: %s\" % acc_train)\n",
        "print(\"Accuracy Test: %s\" % acc_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "frequent-convention",
      "metadata": {
        "id": "frequent-convention"
      },
      "outputs": [],
      "source": [
        "#save model\n",
        "import pickle\n",
        "pickle.dump(model,open('svr.pkl','wb'))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}